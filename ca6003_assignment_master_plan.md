# CA6003 æ•°æ®æ²»ç†ä¸å‡†å¤‡ä½œä¸š - é«˜åˆ†ä½œæˆ˜è®¡åˆ’

## ğŸ“‹ ä½œä¸šæ ¸å¿ƒè¦æ±‚è§£æ

### ğŸ¯ å…³é”®ç†å¿µï¼ˆå¿…é¡»ç†è§£ï¼ï¼‰
```
âš ï¸ é‡ç‚¹è­¦å‘Šï¼šè¿™ä¸æ˜¯ä¸€ä¸ªè¿½æ±‚æ¨¡å‹å‡†ç¡®ç‡çš„ä½œä¸šï¼
âœ… æ ¸å¿ƒç›®æ ‡ï¼šè¯æ˜æ•°æ®å‡†å¤‡çš„é‡è¦æ€§ï¼Œè€Œéæ¨¡å‹æ€§èƒ½
âœ… è¯„åˆ†é‡ç‚¹ï¼šè§£é‡Šã€æ¨ç†ã€æ´å¯Ÿ > å‡†ç¡®ç‡
```

### ğŸ“Š è¯„åˆ†æ ‡å‡†æ‹†è§£ï¼ˆæ€»åˆ†90%ï¼‰

| ç»´åº¦ | å æ¯” | æ ¸å¿ƒè¦æ±‚ | å¦‚ä½•æ‹¿é«˜åˆ† |
|------|------|----------|-----------|
| **Appropriateness** | 25% | é€‰æ‹©åˆé€‚çš„åˆ†ææŠ€æœ¯å’Œå¯è§†åŒ– | åœ¨æ¯ä¸ªé˜¶æ®µéƒ½ç”¨**æ­£ç¡®ä¸”å¤šæ ·**çš„æ–¹æ³• |
| **Correctness & Clarity** | 25% | æŠ€æœ¯æ­£ç¡®æ€§ + æ¸…æ™°è¡¨è¾¾ | æ¯ä¸ªå†³ç­–éƒ½æœ‰**æ˜ç¡®çš„ç†ç”±å’Œè¯æ®** |
| **Data Interpretation** | 25% | åˆ†æåˆ¤æ–­åŠ›ï¼ˆè¯†åˆ«åå·®ã€è°¬è¯¯ï¼‰ | å±•ç¤º**æ·±åº¦åˆ†æ**ï¼ŒæŠ“ä½Simpson's paradoxç­‰ |
| **Novelty & Depth** | 25% | åŸåˆ›æ€§å’Œæ·±åº¦æ´å¯Ÿ | é€‰**æœ‰è¶£çš„æ•°æ®é›†**ï¼Œåš**éå¸¸è§„åˆ†æ** |

---

## ğŸš€ é«˜åˆ†ä½œä¸šæµç¨‹ï¼ˆ7æ­¥èµ°ï¼‰

### **é˜¶æ®µ1ï¼šæ•°æ®é›†é€‰æ‹©ï¼ˆWeek 1ï¼ŒDay 1-2ï¼‰**

#### ç›®æ ‡ï¼šé€‰ä¸€ä¸ª"æœ‰æ•…äº‹"çš„æ•°æ®é›†

**âŒ é¿å…é€‰æ‹©ï¼š**
- Irisã€Titanicç­‰çƒ‚å¤§è¡—æ•°æ®é›†
- å¤ªå¹²å‡€çš„æ•°æ®ï¼ˆæ²¡æ³•å±•ç¤ºæ¸…æ´—æŠ€å·§ï¼‰
- å¤ªå¤æ‚çš„æ•°æ®ï¼ˆç†è§£æˆæœ¬é«˜ï¼‰

**âœ… æ¨èé€‰æ‹©ç‰¹å¾ï¼š**
1. **æœ‰ç°å®æ„ä¹‰**ï¼šåŒ»ç–—ã€é‡‘èã€ç¤¾ä¼šé—®é¢˜
2. **æœ‰æ˜æ˜¾é—®é¢˜**ï¼šç¼ºå¤±å€¼ã€ç¦»ç¾¤å€¼ã€ç±»åˆ«ä¸å¹³è¡¡
3. **æœ‰æ½œåœ¨åå·®**ï¼šæ€§åˆ«ã€å¹´é¾„ã€åœ°åŸŸç­‰bias
4. **ä¸­ç­‰è§„æ¨¡**ï¼š5000-50000è¡Œï¼Œ10-30åˆ—

**ğŸ¯ æ¨èæ•°æ®é›†ï¼š**
```
ä¼˜å…ˆçº§1ï¼ˆå¼ºçƒˆæ¨èï¼‰ï¼š
- Credit Card Fraud Detection (Kaggle)
  â†’ æåº¦ä¸å¹³è¡¡ï¼Œæœ‰æ˜æ˜¾ç¦»ç¾¤å€¼ï¼Œç°å®æ„ä¹‰å¼º
  
- Adult Income Dataset (UCI)
  â†’ æœ‰æ€§åˆ«/ç§æ—biasï¼Œç¼ºå¤±å€¼å¤šï¼Œç¤¾ä¼šæ„ä¹‰å¼º
  
- Healthcare/Medical datasets (Kaggle)
  â†’ ç¼ºå¤±å€¼å¤šï¼Œåæ€åˆ†å¸ƒï¼Œä¼¦ç†é—®é¢˜çªå‡º

ä¼˜å…ˆçº§2ï¼ˆå¤‡é€‰ï¼‰ï¼š
- Singapore HDB Resale Prices (data.gov.sg)
  â†’ æœ¬åœ°æ•°æ®ï¼Œæ—¶é—´åºåˆ—ï¼Œåœ°åŸŸåå·®
  
- Employee Attrition (Kaggle)
  â†’ ç±»åˆ«ä¸å¹³è¡¡ï¼Œç‰¹å¾å·¥ç¨‹ç©ºé—´å¤§
```

**é€‰æ‹©æ ‡å‡†æ¸…å•ï¼š**
```python
âœ… æ•°æ®é›†è¯„ä¼°checklistï¼š
â–¡ æ˜¯å¦æœ‰>10%ç¼ºå¤±å€¼ï¼Ÿ
â–¡ æ˜¯å¦æœ‰æ˜æ˜¾ç¦»ç¾¤å€¼ï¼Ÿ
â–¡ æ˜¯å¦æœ‰ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Ÿ
â–¡ æ˜¯å¦æœ‰æ½œåœ¨biasï¼ˆæ€§åˆ«/å¹´é¾„/åœ°åŸŸï¼‰ï¼Ÿ
â–¡ æ˜¯å¦æœ‰ç°å®æ„ä¹‰å’Œæ•…äº‹æ€§ï¼Ÿ
â–¡ æ˜¯å¦é€‚åˆç”¨ç®€å•æ¨¡å‹ï¼ˆçº¿æ€§/é€»è¾‘/å†³ç­–æ ‘ï¼‰ï¼Ÿ
â–¡ æ•°æ®é‡æ˜¯å¦é€‚ä¸­ï¼ˆ5k-50kè¡Œï¼‰ï¼Ÿ

å¦‚æœæœ‰5ä¸ªä»¥ä¸Šâœ… â†’ é€‰è¿™ä¸ªï¼
```

---

### **é˜¶æ®µ2ï¼šæ•°æ®Profiling & EDAï¼ˆWeek 1-2ï¼ŒDay 3-7ï¼‰**

#### ç›®æ ‡ï¼šå…¨æ–¹ä½ä½“æ£€æ•°æ®ï¼Œæ‰¾å‡ºæ‰€æœ‰é—®é¢˜

**ğŸ“Š å¿…åšåˆ†æï¼ˆæ‹¿æ»¡25%çš„Appropriatenessåˆ†ï¼‰ï¼š**

#### 2.1 åŸºç¡€Profiling
```python
å¿…é¡»åŒ…å«çš„å†…å®¹ï¼š
1. æ•°æ®é›†æ¦‚è§ˆ
   - è¡Œæ•°ã€åˆ—æ•°ã€å†…å­˜å ç”¨
   - æ•°æ®ç±»å‹åˆ†å¸ƒï¼ˆæ•°å€¼/ç±»åˆ«/æ—¥æœŸï¼‰
   - ç›®æ ‡å˜é‡åˆ†å¸ƒ

2. ç¼ºå¤±å€¼åˆ†æ
   - æ¯åˆ—ç¼ºå¤±ç‡
   - ç¼ºå¤±æ¨¡å¼å¯è§†åŒ–ï¼ˆmissingnoåº“ï¼‰
   - ç¼ºå¤±å€¼ç›¸å…³æ€§åˆ†æï¼ˆMCAR/MAR/MNARåˆ¤æ–­ï¼‰

3. æ•°å€¼ç‰¹å¾åˆ†æ
   - äº”æ•°æ¦‚æ‹¬ï¼ˆmin, Q1, median, Q3, maxï¼‰
   - ååº¦(skewness)å’Œå³°åº¦(kurtosis)
   - ç›´æ–¹å›¾ + å¯†åº¦å›¾

4. ç±»åˆ«ç‰¹å¾åˆ†æ
   - ç±»åˆ«æ•°é‡å’Œåˆ†å¸ƒ
   - é«˜åŸºæ•°é—®é¢˜è¯†åˆ«
   - ç¨€æœ‰ç±»åˆ«æ£€æµ‹
```

#### 2.2 é«˜çº§åˆ†æï¼ˆæ‹¿Noveltyåˆ†çš„å…³é”®ï¼ï¼‰
```python
è¿›é˜¶å†…å®¹ï¼ˆå±•ç¤ºæ·±åº¦ï¼‰ï¼š

1. ç¦»ç¾¤å€¼æ£€æµ‹ï¼ˆå¤šç§æ–¹æ³•å¯¹æ¯”ï¼‰
   âœ… IQRæ–¹æ³•
   âœ… Z-scoreæ–¹æ³•
   âœ… Isolation Forest
   âœ… ç®±å‹å›¾å¯è§†åŒ–
   â†’ å…³é”®ï¼šè§£é‡Šä¸ºä»€ä¹ˆç¦»ç¾¤ï¼ˆåƒä½ PPTé‡Œçš„"whales"ï¼‰

2. ç›¸å…³æ€§åˆ†æï¼ˆè¯†åˆ«è°¬è¯¯çš„æœºä¼šï¼ï¼‰
   âœ… Pearsonç›¸å…³çŸ©é˜µçƒ­åŠ›å›¾
   âœ… Spearmanç›¸å…³ï¼ˆéçº¿æ€§å…³ç³»ï¼‰
   âœ… è¯†åˆ«å¤šé‡å…±çº¿æ€§ï¼ˆVIFï¼‰
   âš ï¸ å¼ºè°ƒï¼šCorrelation â‰  Causationï¼
   
3. åˆ†å¸ƒåˆ†æ
   âœ… QQ Plotï¼ˆæ£€éªŒæ­£æ€æ€§ï¼‰
   âœ… åæ€è¯†åˆ«ï¼ˆå·¦å/å³å/åŒå³°ï¼‰
   âœ… å¯¹æ•°å˜æ¢å‰åå¯¹æ¯”

4. Biasæ£€æµ‹ï¼ˆé‡ç‚¹ï¼ï¼‰
   âœ… æŒ‰æ€§åˆ«/å¹´é¾„/åœ°åŸŸåˆ†ç»„ç»Ÿè®¡
   âœ… æ£€éªŒç»Ÿè®¡æ˜¾è‘—æ€§ï¼ˆt-test/chi-squareï¼‰
   âœ… å¯è§†åŒ–ç¾¤ä½“å·®å¼‚ï¼ˆåˆ†ç»„ç®±å‹å›¾ï¼‰
   
5. Simpson's Paradoxæ£€æµ‹
   âœ… æ•´ä½“è¶‹åŠ¿ vs åˆ†ç»„è¶‹åŠ¿å¯¹æ¯”
   âœ… ç”¨å®ä¾‹è¯´æ˜åè½¬ç°è±¡
   â†’ è¿™æ˜¯æ‹¿Noveltyåˆ†çš„é‡‘çŸ¿ï¼
```

#### ğŸ¨ å¯è§†åŒ–è¦æ±‚
```
æ¯ä¸ªåˆ†æéƒ½è¦é…å›¾ï¼Œä¸”å›¾è¦è®²æ•…äº‹ï¼š

åŸºç¡€å¯è§†åŒ–ï¼ˆå¿…é¡»æœ‰ï¼‰ï¼š
- ç¼ºå¤±å€¼çƒ­åŠ›å›¾
- æ•°å€¼ç‰¹å¾åˆ†å¸ƒå›¾ï¼ˆç›´æ–¹å›¾+KDEï¼‰
- ç›¸å…³çŸ©é˜µçƒ­åŠ›å›¾
- ç®±å‹å›¾ï¼ˆç¦»ç¾¤å€¼æ£€æµ‹ï¼‰
- ç±»åˆ«ç‰¹å¾æŸ±çŠ¶å›¾

é«˜çº§å¯è§†åŒ–ï¼ˆåŠ åˆ†é¡¹ï¼‰ï¼š
- QQ Plot
- Pair Plotï¼ˆç‰¹å¾ä¸¤ä¸¤å…³ç³»ï¼‰
- Violin Plotï¼ˆåˆ†å¸ƒ+ç®±å‹å›¾ç»“åˆï¼‰
- åˆ†ç»„å¯¹æ¯”å›¾ï¼ˆæ˜¾ç¤ºbiasï¼‰
- æ—¶é—´åºåˆ—å›¾ï¼ˆå¦‚æœæœ‰æ—¶é—´ç»´åº¦ï¼‰

âš ï¸ å›¾è¡¨è®¾è®¡åŸåˆ™ï¼š
1. æ¯ä¸ªå›¾éƒ½è¦æœ‰æ ‡é¢˜ã€è½´æ ‡ç­¾ã€å›¾ä¾‹
2. ä½¿ç”¨è‰²ç›²å‹å¥½çš„é…è‰²
3. å›¾ä¸è¦å¤ªå¯†é›†ï¼ˆä¸€é¡µæœ€å¤š2-3ä¸ªå›¾ï¼‰
4. æ¯ä¸ªå›¾åé¢éƒ½è¦æœ‰æ–‡å­—è§£é‡Š
```

---

### **é˜¶æ®µ3ï¼šæ•°æ®æ¸…æ´—ä¸è½¬æ¢ï¼ˆWeek 2ï¼ŒDay 1-3ï¼‰**

#### ç›®æ ‡ï¼šå±•ç¤ºæ•°æ®å‡†å¤‡çš„é‡è¦æ€§

**ğŸ”§ å¿…åšæ­¥éª¤ï¼ˆè¦æœ‰Before/Afterå¯¹æ¯”ï¼ï¼‰ï¼š**

#### 3.1 ç¼ºå¤±å€¼å¤„ç†
```python
å¿…é¡»å±•ç¤ºå¤šç§æ–¹æ³•çš„å¯¹æ¯”ï¼š

æ–¹æ³•1ï¼šåˆ é™¤
- é€‚ç”¨åœºæ™¯ï¼šç¼ºå¤±ç‡<5%
- å†³ç­–ç†ç”±ï¼šç®€å•ä¸”ä¸å½±å“åˆ†å¸ƒ
- Before/Afterå¯¹æ¯”ï¼šæ ·æœ¬é‡å˜åŒ–

æ–¹æ³•2ï¼šå¡«è¡¥
- å‡å€¼/ä¸­ä½æ•°å¡«è¡¥ï¼ˆæ•°å€¼å‹ï¼‰
- ä¼—æ•°å¡«è¡¥ï¼ˆç±»åˆ«å‹ï¼‰
- å‰å‘/åå‘å¡«å……ï¼ˆæ—¶é—´åºåˆ—ï¼‰
- KNNå¡«è¡¥ï¼ˆé«˜çº§æ–¹æ³•ï¼‰
- å†³ç­–ç†ç”±ï¼šä¿ç•™æ ·æœ¬é‡ï¼Œå¡«è¡¥å€¼åˆç†

æ–¹æ³•3ï¼šæ ‡è®°ç¼ºå¤±
- åˆ›å»ºis_missingæŒ‡ç¤ºå˜é‡
- å†³ç­–ç†ç”±ï¼šç¼ºå¤±æœ¬èº«å¯èƒ½æœ‰ä¿¡æ¯

âš ï¸ å…³é”®ï¼šæ¯ä¸ªå†³ç­–éƒ½è¦justifyï¼
```

#### 3.2 ç¦»ç¾¤å€¼å¤„ç†
```python
ç­–ç•¥å¯¹æ¯”ï¼ˆè¿™æ˜¯é‡ç‚¹ï¼ï¼‰ï¼š

ç­–ç•¥Aï¼šä¿ç•™
- ç†ç”±ï¼šä»£è¡¨çœŸå®é«˜ä»·å€¼å®¢æˆ·ï¼ˆåƒä½ PPTï¼‰
- è¯æ®ï¼šä¸šåŠ¡åˆ†æ + é¢†åŸŸçŸ¥è¯†

ç­–ç•¥Bï¼šåˆ é™¤
- ç†ç”±ï¼šæç«¯å€¼ä¼šå½±å“æ¨¡å‹
- è¯æ®ï¼šç»Ÿè®¡æ£€éªŒï¼ˆ>3Ïƒï¼‰

ç­–ç•¥Cï¼šWinsorizationï¼ˆæˆªå°¾ï¼‰
- ç†ç”±ï¼šä¿ç•™ä¿¡æ¯ä½†å‡å°‘å½±å“
- æ–¹æ³•ï¼šæ›¿æ¢ä¸º99th percentile

ç­–ç•¥Dï¼šè½¬æ¢
- ç†ç”±ï¼šé€šè¿‡å˜æ¢å‡å°‘å½±å“
- æ–¹æ³•ï¼šlogå˜æ¢ã€Box-Cox

âš ï¸ æ¯ä¸ªç­–ç•¥éƒ½è¦å®éªŒï¼Œå¯¹æ¯”å½±å“ï¼
```

#### 3.3 ç‰¹å¾å·¥ç¨‹
```python
åŸºç¡€å·¥ç¨‹ï¼š
1. ç¼–ç 
   - One-Hot Encodingï¼ˆä½åŸºæ•°ç±»åˆ«ï¼‰
   - Label Encodingï¼ˆæœ‰åºç±»åˆ«ï¼‰
   - Target Encodingï¼ˆé«˜åŸºæ•°ç±»åˆ«ï¼‰

2. ç¼©æ”¾
   - StandardScalerï¼ˆæ­£æ€åˆ†å¸ƒï¼‰
   - MinMaxScalerï¼ˆæœ‰ç•Œæ•°æ®ï¼‰
   - RobustScalerï¼ˆæœ‰ç¦»ç¾¤å€¼ï¼‰

3. åˆ†ç®±ï¼ˆBinningï¼‰
   - ç­‰å®½åˆ†ç®±
   - ç­‰é¢‘åˆ†ç®±
   - è‡ªå®šä¹‰åˆ†ç®±ï¼ˆä¸šåŠ¡é€»è¾‘ï¼‰

é«˜çº§å·¥ç¨‹ï¼ˆåŠ åˆ†é¡¹ï¼‰ï¼š
4. äº¤äº’ç‰¹å¾
   - ç‰¹å¾ç›¸ä¹˜/ç›¸åŠ 
   - å¤šé¡¹å¼ç‰¹å¾

5. æ—¶é—´ç‰¹å¾
   - æå–å¹´/æœˆ/æ—¥/å‘¨å‡ 
   - å‘¨æœŸæ€§ç¼–ç ï¼ˆsin/cosï¼‰

6. é¢†åŸŸçŸ¥è¯†ç‰¹å¾
   - å¦‚ï¼šBMI = weight / height^2
   - æ”¶å…¥è´Ÿå€ºæ¯” = debt / income

âš ï¸ æ¯ä¸ªç‰¹å¾éƒ½è¦è§£é‡Šä¸ºä»€ä¹ˆåˆ›å»ºï¼
```

#### 3.4 Biasç¼“è§£
```python
å¿…é¡»å±•ç¤ºçš„ç­–ç•¥ï¼š

1. é‡é‡‡æ ·
   - Oversamplingå°‘æ•°ç¾¤ä½“
   - Undersamplingå¤šæ•°ç¾¤ä½“
   - SMOTEï¼ˆä½†è¦è¯´æ˜ä¸ºä»€ä¹ˆç”¨/ä¸ç”¨ï¼‰

2. é‡åŠ æƒ
   - ç»™ä¸åŒç¾¤ä½“ä¸åŒæƒé‡
   - å¹³è¡¡è®­ç»ƒé›†

3. å…¬å¹³æ€§çº¦æŸ
   - ç¡®ä¿ä¸åŒç¾¤ä½“æœ‰ç›¸ä¼¼ç»“æœ
   - Demographic parityæ£€éªŒ

âš ï¸ å…³é”®ï¼šè®¨è®ºtrade-offï¼ˆå…¬å¹³ vs æ€§èƒ½ï¼‰
```

---

### **é˜¶æ®µ4ï¼šåˆ›å»ºå¯¹æ¯”ç‰ˆæœ¬ï¼ˆWeek 2ï¼ŒDay 4ï¼‰**

#### ç›®æ ‡ï¼šåˆ¶é€ "æˆå‰§æ€§å¯¹æ¯”"

**ğŸ“¦ å¿…é¡»å‡†å¤‡çš„æ•°æ®ç‰ˆæœ¬ï¼š**

```python
ç‰ˆæœ¬1ï¼šMinimal Processingï¼ˆåŸºçº¿ï¼‰
- åªåˆ é™¤å®Œå…¨ç©ºè¡Œ
- ä¸åšä»»ä½•å¡«è¡¥
- ä¸å¤„ç†ç¦»ç¾¤å€¼
- ä¸åšç‰¹å¾å·¥ç¨‹
- åªåšæœ€åŸºæœ¬ç¼–ç 
â†’ ç›®çš„ï¼šä½œä¸º"åä¾‹å­"

ç‰ˆæœ¬2ï¼šFull Preparationï¼ˆå®Œæ•´ç‰ˆï¼‰
- åˆç†å¤„ç†ç¼ºå¤±å€¼
- å¤„ç†ç¦»ç¾¤å€¼ï¼ˆæœ‰ç†æœ‰æ®ï¼‰
- å®Œæ•´ç‰¹å¾å·¥ç¨‹
- Biasç¼“è§£
- æ‰€æœ‰è½¬æ¢ä¼˜åŒ–
â†’ ç›®çš„ï¼šå±•ç¤ºæœ€ä½³å®è·µ

ç‰ˆæœ¬3ï¼šOver-processingï¼ˆå¯é€‰ï¼ŒåŠ åˆ†é¡¹ï¼‰
- è¿‡åº¦åˆ é™¤æ•°æ®
- æ¿€è¿›å¤„ç†ç¦»ç¾¤å€¼
- è¿‡åº¦ç‰¹å¾å·¥ç¨‹
â†’ ç›®çš„ï¼šè¯´æ˜"è¿‡çŠ¹ä¸åŠ"

âš ï¸ æ¯ä¸ªç‰ˆæœ¬éƒ½è¦è®°å½•ï¼š
- æ ·æœ¬é‡å˜åŒ–
- ç‰¹å¾æ•°é‡å˜åŒ–
- åˆ†å¸ƒå˜åŒ–
- å¤„ç†å†³ç­–æ—¥å¿—
```

---

### **é˜¶æ®µ5ï¼šç®€å•æ¨¡å‹å¯¹æ¯”ï¼ˆWeek 3ï¼ŒDay 1-3ï¼‰**

#### ç›®æ ‡ï¼šç”¨MLè¯æ˜æ•°æ®å‡†å¤‡çš„é‡è¦æ€§

**ğŸ¤– å¿…é¡»ä½¿ç”¨çš„æ¨¡å‹ï¼ˆåªèƒ½ç”¨ç®€å•æ¨¡å‹ï¼ï¼‰ï¼š**

```python
åœºæ™¯1ï¼šåˆ†ç±»é—®é¢˜
ä¸»æ¨¡å‹ï¼šLogistic Regression
å¯¹æ¯”æ¨¡å‹ï¼šDecision Treeï¼ˆæ·±åº¦é™åˆ¶â‰¤5ï¼‰

åœºæ™¯2ï¼šå›å½’é—®é¢˜
ä¸»æ¨¡å‹ï¼šLinear Regression
å¯¹æ¯”æ¨¡å‹ï¼šDecision Tree Regressorï¼ˆæ·±åº¦é™åˆ¶â‰¤5ï¼‰

âš ï¸ ä¸¥æ ¼ç¦æ­¢ï¼š
- Random Forest
- XGBoost
- Neural Networks
- SVMï¼ˆå¤æ‚æ ¸å‡½æ•°ï¼‰
â†’ ç”¨äº†ä¼šæ‰£åˆ†ï¼
```

**ğŸ“Š å¯¹æ¯”å®éªŒè®¾è®¡ï¼š**

```python
å®éªŒ1ï¼šåŸºçº¿ vs å®Œæ•´å‡†å¤‡
æ•°æ®ï¼šMinimal vs Full
æ¨¡å‹ï¼šç›¸åŒæ¨¡å‹ï¼ˆå¦‚Logistic Regressionï¼‰
è¯„ä¼°ï¼šå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ã€AUC

å®éªŒ2ï¼šä¸åŒå¤„ç†ç­–ç•¥å¯¹æ¯”
ä¾‹å¦‚ï¼š
- åˆ é™¤ç¦»ç¾¤å€¼ vs ä¿ç•™ç¦»ç¾¤å€¼
- å¡«è¡¥ç¼ºå¤± vs åˆ é™¤ç¼ºå¤±
- æœ‰ç‰¹å¾å·¥ç¨‹ vs æ— ç‰¹å¾å·¥ç¨‹

å®éªŒ3ï¼šBiaså½±å“
å¯¹æ¯”ï¼š
- åŸå§‹æ•°æ®çš„ç¾¤ä½“å·®å¼‚
- ç¼“è§£åçš„ç¾¤ä½“å·®å¼‚
- Fairness metricsï¼ˆDemographic Parity, Equal Opportunityï¼‰

âš ï¸ è¯„ä¼°é‡ç‚¹ï¼š
âœ… è§£é‡Šæ€§èƒ½å·®å¼‚çš„åŸå› 
âœ… ç‰¹å¾é‡è¦æ€§åˆ†æ
âœ… é”™è¯¯æ¡ˆä¾‹åˆ†æ
âœ… æ®‹å·®åˆ†æï¼ˆå›å½’é—®é¢˜ï¼‰
âœ… æ··æ·†çŸ©é˜µåˆ†æï¼ˆåˆ†ç±»é—®é¢˜ï¼‰

âŒ ä¸è¦ï¼š
- ç›²ç›®è°ƒå‚
- è¿½æ±‚æœ€é«˜å‡†ç¡®ç‡
- ä½¿ç”¨å¤æ‚æ¨¡å‹
```

**ğŸ“ˆ å¿…é¡»çš„å¯è§†åŒ–ï¼š**
```
1. æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾
   - ä¸åŒç‰ˆæœ¬çš„å‡†ç¡®ç‡å¯¹æ¯”
   - ä¸åŒæŒ‡æ ‡ï¼ˆPrecision/Recall/F1ï¼‰å¯¹æ¯”

2. ROCæ›²çº¿å¯¹æ¯”
   - Minimal vs Fullçš„ROCæ›²çº¿
   - AUCå·®å¼‚æ ‡æ³¨

3. ç‰¹å¾é‡è¦æ€§å›¾
   - å±•ç¤ºå“ªäº›æ–°ç‰¹å¾æœ€æœ‰ç”¨
   - åŸå§‹ç‰¹å¾ vs å·¥ç¨‹ç‰¹å¾

4. å­¦ä¹ æ›²çº¿
   - è®­ç»ƒé›† vs éªŒè¯é›†æ€§èƒ½
   - åˆ¤æ–­è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ

5. æ®‹å·®å›¾ï¼ˆå›å½’ï¼‰/ æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»ï¼‰
   - å±•ç¤ºé¢„æµ‹é”™è¯¯çš„æ¨¡å¼
   - åˆ†ææ”¹è¿›ç©ºé—´

6. Fairnesså¯¹æ¯”å›¾
   - ä¸åŒç¾¤ä½“çš„æ€§èƒ½å·®å¼‚
   - ç¼“è§£å‰åå¯¹æ¯”
```

---

### **é˜¶æ®µ6ï¼šJupyter Notebookæ’°å†™ï¼ˆWeek 3ï¼ŒDay 4-7ï¼‰**

#### ç›®æ ‡ï¼šåˆ¶ä½œä¸€ä¸ª"æ•™ç§‘ä¹¦çº§"çš„Notebook

**ğŸ““ Notebookç»“æ„ï¼ˆä¸¥æ ¼æŒ‰æ­¤ç»„ç»‡ï¼ï¼‰ï¼š**

```markdown
# é¡¹ç›®æ ‡é¢˜
Group X - [æ•°æ®é›†åç§°] æ•°æ®å‡†å¤‡ä¸åˆ†æ

## ç›®å½•
1. é¡¹ç›®æ¦‚è¿°
2. æ•°æ®è·å–ä¸åŠ è½½
3. æ•°æ®Profiling
4. æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰
5. æ•°æ®æ¸…æ´—ä¸è½¬æ¢
6. ç‰¹å¾å·¥ç¨‹
7. Biasæ£€æµ‹ä¸ç¼“è§£
8. æ¨¡å‹å¯¹æ¯”å®éªŒ
9. ç»“æœåˆ†æä¸æ´å¯Ÿ
10. æ€»ç»“ä¸åæ€

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 èƒŒæ™¯ä¸ç›®æ ‡
**ä¸šåŠ¡èƒŒæ™¯ï¼š**
[ç”¨2-3æ®µè¯æè¿°æ•°æ®é›†çš„ç°å®æ„ä¹‰]

**åˆ†æç›®æ ‡ï¼š**
- ç›®æ ‡1ï¼š...
- ç›®æ ‡2ï¼š...
- ç›®æ ‡3ï¼š...

**å…³é”®é—®é¢˜ï¼š**
1. é—®é¢˜1ï¼š...
2. é—®é¢˜2ï¼š...
3. é—®é¢˜3ï¼š...

### 1.2 æ•°æ®é›†æè¿°
- **æ¥æºï¼š** [é“¾æ¥]
- **æ ·æœ¬é‡ï¼š** Xè¡Œ
- **ç‰¹å¾æ•°ï¼š** Yåˆ—
- **ç›®æ ‡å˜é‡ï¼š** [åç§°åŠå«ä¹‰]
- **æ—¶é—´èŒƒå›´ï¼š** [å¦‚é€‚ç”¨]

### 1.3 å·¥å…·ä¸åº“
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# è®¾ç½®
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
pd.set_option('display.max_columns', None)
```

---

## 2. æ•°æ®è·å–ä¸åŠ è½½

### 2.1 æ•°æ®åŠ è½½
```python
# åŠ è½½æ•°æ®
df = pd.read_csv('data.csv')

# åˆæ­¥æŸ¥çœ‹
print(f"æ•°æ®é›†å½¢çŠ¶: {df.shape}")
df.head()
```

### 2.2 æ•°æ®å­—å…¸
| åˆ—å | ç±»å‹ | æè¿° | å–å€¼èŒƒå›´ |
|------|------|------|----------|
| ... | ... | ... | ... |

---

## 3. æ•°æ®Profiling

### 3.1 åŸºç¡€ä¿¡æ¯
```python
# æ•°æ®ç±»å‹
df.info()

# æ•°å€¼ç»Ÿè®¡
df.describe()

# ç¼ºå¤±å€¼ç»Ÿè®¡
missing = df.isnull().sum()
missing[missing > 0]
```

### 3.2 ç¼ºå¤±å€¼åˆ†æ
```python
import missingno as msno

# ç¼ºå¤±å€¼å¯è§†åŒ–
msno.matrix(df)
plt.title('Missing Data Pattern')
plt.show()

# ç¼ºå¤±å€¼ç›¸å…³æ€§
msno.heatmap(df)
plt.title('Missing Data Correlation')
plt.show()
```

**åˆ†æç»“è®ºï¼š**
- è§‚å¯Ÿ1ï¼š...
- è§‚å¯Ÿ2ï¼š...
- ç¼ºå¤±æœºåˆ¶åˆ¤æ–­ï¼šMCAR/MAR/MNARï¼Ÿ

---

## 4. æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰

### 4.1 ç›®æ ‡å˜é‡åˆ†æ
```python
# åˆ†å¸ƒ
df['target'].value_counts()

# å¯è§†åŒ–
plt.figure(figsize=(8, 6))
df['target'].value_counts().plot(kind='bar')
plt.title('Target Variable Distribution')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()
```

**å…³é”®å‘ç°ï¼š**
- ç±»åˆ«å¹³è¡¡æƒ…å†µï¼š...
- æ˜¯å¦éœ€è¦å¤„ç†ï¼š...

### 4.2 æ•°å€¼ç‰¹å¾åˆ†æ
```python
# é€‰æ‹©æ•°å€¼åˆ—
numeric_cols = df.select_dtypes(include=[np.number]).columns

# åˆ†å¸ƒå›¾
fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))
for idx, col in enumerate(numeric_cols[:9]):
    ax = axes[idx // 3, idx % 3]
    df[col].hist(bins=30, ax=ax, edgecolor='black')
    ax.set_title(f'{col} Distribution')
    ax.set_xlabel(col)
    ax.set_ylabel('Frequency')
plt.tight_layout()
plt.show()

# ååº¦å’Œå³°åº¦
skewness = df[numeric_cols].skew()
kurtosis = df[numeric_cols].kurtosis()
print("Skewness:\n", skewness[abs(skewness) > 1])
print("\nKurtosis:\n", kurtosis[abs(kurtosis) > 3])
```

**åˆ†æï¼š**
- é«˜åº¦åæ€ç‰¹å¾ï¼š[åˆ—ä¸¾]
- æ½œåœ¨ç¦»ç¾¤å€¼ç‰¹å¾ï¼š[åˆ—ä¸¾]
- å»ºè®®è½¬æ¢ï¼š[åˆ—ä¸¾]

### 4.3 ç±»åˆ«ç‰¹å¾åˆ†æ
```python
# ç±»åˆ«åˆ—
categorical_cols = df.select_dtypes(include=['object']).columns

# å”¯ä¸€å€¼ç»Ÿè®¡
for col in categorical_cols:
    print(f"{col}: {df[col].nunique()} unique values")
    print(df[col].value_counts().head())
    print("-" * 50)

# é«˜åŸºæ•°æ£€æµ‹
high_cardinality = [col for col in categorical_cols 
                    if df[col].nunique() > 10]
print(f"High cardinality features: {high_cardinality}")
```

### 4.4 ç¦»ç¾¤å€¼æ£€æµ‹
```python
# ç®±å‹å›¾
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))
for idx, col in enumerate(numeric_cols[:6]):
    ax = axes[idx // 3, idx % 3]
    df.boxplot(column=col, ax=ax)
    ax.set_title(f'{col} Boxplot')
plt.tight_layout()
plt.show()

# IQRæ–¹æ³•æ£€æµ‹
def detect_outliers_iqr(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    outliers = df[(df[col] < lower) | (df[col] > upper)]
    return outliers, lower, upper

# æ£€æµ‹æ¯åˆ—
for col in numeric_cols:
    outliers, lower, upper = detect_outliers_iqr(df, col)
    print(f"{col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.2f}%)")
```

**ç¦»ç¾¤å€¼å†³ç­–ï¼š**
| ç‰¹å¾ | ç¦»ç¾¤å€¼% | å†³ç­– | ç†ç”± |
|------|---------|------|------|
| ... | ... | ä¿ç•™/åˆ é™¤/è½¬æ¢ | ... |

### 4.5 ç›¸å…³æ€§åˆ†æ
```python
# ç›¸å…³çŸ©é˜µ
corr_matrix = df[numeric_cols].corr()

# çƒ­åŠ›å›¾
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Correlation Matrix')
plt.show()

# é«˜ç›¸å…³æ€§æ£€æµ‹
high_corr = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) > 0.8:
            high_corr.append((corr_matrix.columns[i], 
                            corr_matrix.columns[j], 
                            corr_matrix.iloc[i, j]))

print("High correlation pairs:")
for pair in high_corr:
    print(f"{pair[0]} vs {pair[1]}: {pair[2]:.3f}")
```

**âš ï¸ ç›¸å…³æ€§â‰ å› æœæ€§è­¦å‘Š**
[ä¸¾ä¾‹è¯´æ˜correlation vs causation]

### 4.6 QQ Plotï¼ˆæ­£æ€æ€§æ£€éªŒï¼‰
```python
from scipy import stats

fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))
for idx, col in enumerate(numeric_cols[:6]):
    ax = axes[idx // 3, idx % 3]
    stats.probplot(df[col].dropna(), dist="norm", plot=ax)
    ax.set_title(f'{col} Q-Q Plot')
plt.tight_layout()
plt.show()
```

**æ­£æ€æ€§ç»“è®ºï¼š**
- ç¬¦åˆæ­£æ€ï¼š[åˆ—ä¸¾]
- éœ€è¦è½¬æ¢ï¼š[åˆ—ä¸¾]

### 4.7 Biasæ£€æµ‹ï¼ˆé‡ç‚¹ï¼ï¼‰
```python
# å‡è®¾æœ‰genderåˆ—
if 'gender' in df.columns:
    # åˆ†ç»„ç»Ÿè®¡
    grouped = df.groupby('gender')[numeric_cols].mean()
    print(grouped)
    
    # å¯è§†åŒ–å¯¹æ¯”
    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))
    for idx, col in enumerate(['income', 'loan_amount', 'credit_score']):
        ax = axes[idx]
        df.boxplot(column=col, by='gender', ax=ax)
        ax.set_title(f'{col} by Gender')
    plt.tight_layout()
    plt.show()
    
    # ç»Ÿè®¡æ£€éªŒ
    from scipy.stats import ttest_ind
    male_income = df[df['gender'] == 'Male']['income']
    female_income = df[df['gender'] == 'Female']['income']
    t_stat, p_value = ttest_ind(male_income, female_income)
    print(f"T-test: t={t_stat:.3f}, p={p_value:.3f}")
    if p_value < 0.05:
        print("âš ï¸ Significant difference detected - potential bias!")
```

### 4.8 Simpson's Paradoxæ£€æµ‹ï¼ˆåŠ åˆ†é¡¹ï¼ï¼‰
```python
# ç¤ºä¾‹ï¼šæ•´ä½“è¶‹åŠ¿ vs åˆ†ç»„è¶‹åŠ¿
# [æ ¹æ®ä½ çš„æ•°æ®é›†è®¾è®¡å…·ä½“ä¾‹å­]

# æ•´ä½“ç›¸å…³æ€§
overall_corr = df[['feature1', 'feature2']].corr().iloc[0, 1]
print(f"Overall correlation: {overall_corr:.3f}")

# åˆ†ç»„ç›¸å…³æ€§
for group in df['group_column'].unique():
    subset = df[df['group_column'] == group]
    group_corr = subset[['feature1', 'feature2']].corr().iloc[0, 1]
    print(f"Group {group} correlation: {group_corr:.3f}")

# å¯è§†åŒ–
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='feature1', y='feature2', hue='group_column')
plt.title("Simpson's Paradox Illustration")
plt.show()
```

**Simpson's Paradoxå‘ç°ï¼š**
[è§£é‡Šä½ å‘ç°çš„åè½¬ç°è±¡]

---

## 5. æ•°æ®æ¸…æ´—ä¸è½¬æ¢

### 5.1 åˆ›å»ºæ•°æ®å‰¯æœ¬
```python
# ä¿ç•™åŸå§‹æ•°æ®
df_original = df.copy()

# åˆ›å»ºå¤„ç†ç‰ˆæœ¬
df_minimal = df.copy()  # æœ€å°å¤„ç†
df_full = df.copy()     # å®Œæ•´å¤„ç†
```

### 5.2 Minimal Processing Version
```python
# åªåˆ é™¤å®Œå…¨ç©ºè¡Œ
df_minimal = df_minimal.dropna(how='all')

# åŸºç¡€ç¼–ç 
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for col in categorical_cols:
    df_minimal[col + '_encoded'] = le.fit_transform(df_minimal[col].fillna('missing'))

print(f"Minimal processing: {df_minimal.shape}")
```

### 5.3 Full Preparation Version

#### 5.3.1 ç¼ºå¤±å€¼å¤„ç†
```python
# ç­–ç•¥1ï¼šåˆ é™¤ï¼ˆç¼ºå¤±ç‡<5%çš„åˆ—ï¼‰
low_missing_cols = missing[missing / len(df) < 0.05].index
df_full = df_full.dropna(subset=low_missing_cols)

# ç­–ç•¥2ï¼šå¡«è¡¥ï¼ˆç¼ºå¤±ç‡5-20%çš„åˆ—ï¼‰
medium_missing_cols = missing[(missing / len(df) >= 0.05) & 
                               (missing / len(df) < 0.20)].index

for col in medium_missing_cols:
    if col in numeric_cols:
        # ç”¨ä¸­ä½æ•°å¡«è¡¥ï¼ˆå¯¹ç¦»ç¾¤å€¼é²æ£’ï¼‰
        df_full[col].fillna(df_full[col].median(), inplace=True)
    else:
        # ç”¨ä¼—æ•°å¡«è¡¥
        df_full[col].fillna(df_full[col].mode()[0], inplace=True)

# ç­–ç•¥3ï¼šæ ‡è®°ç¼ºå¤±ï¼ˆç¼ºå¤±ç‡20-50%çš„åˆ—ï¼‰
high_missing_cols = missing[(missing / len(df) >= 0.20) & 
                             (missing / len(df) < 0.50)].index

for col in high_missing_cols:
    df_full[col + '_is_missing'] = df_full[col].isnull().astype(int)
    df_full[col].fillna(df_full[col].median(), inplace=True)

# ç­–ç•¥4ï¼šåˆ é™¤åˆ—ï¼ˆç¼ºå¤±ç‡>50%ï¼‰
df_full = df_full.drop(columns=missing[missing / len(df) > 0.50].index)

print(f"After missing value treatment: {df_full.shape}")
```

**ç¼ºå¤±å€¼å¤„ç†å†³ç­–æ—¥å¿—ï¼š**
| åˆ—å | ç¼ºå¤±ç‡ | ç­–ç•¥ | ç†ç”± |
|------|--------|------|------|
| ... | ... | ... | ... |

#### 5.3.2 ç¦»ç¾¤å€¼å¤„ç†
```python
# å†³ç­–ï¼šä¿ç•™é«˜ä»·å€¼å®¢æˆ·ç¦»ç¾¤å€¼ï¼Œå¤„ç†é”™è¯¯æ•°æ®

# ç¤ºä¾‹ï¼šä¿ç•™æ”¶å…¥ç¦»ç¾¤å€¼ï¼ˆé«˜æ”¶å…¥å®¢æˆ·ï¼‰
# ä½†å¤„ç†å¹´é¾„ç¦»ç¾¤å€¼ï¼ˆå¯èƒ½æ˜¯é”™è¯¯ï¼‰

# å¹´é¾„ç¦»ç¾¤å€¼å¤„ç†
age_outliers, lower, upper = detect_outliers_iqr(df_full, 'age')
print(f"Age outliers: {len(age_outliers)} ({lower:.1f}, {upper:.1f})")

# æˆªå°¾å¤„ç†
df_full['age'] = df_full['age'].clip(lower=lower, upper=upper)

# æ”¶å…¥ç¦»ç¾¤å€¼ä¿ç•™
print("Income outliers retained - represent high-value customers")
```

**ç¦»ç¾¤å€¼å¤„ç†å†³ç­–ï¼š**
- ä¿ç•™ï¼š[åˆ—ä¸¾+ç†ç”±]
- åˆ é™¤ï¼š[åˆ—ä¸¾+ç†ç”±]
- è½¬æ¢ï¼š[åˆ—ä¸¾+ç†ç”±]

#### 5.3.3 ç‰¹å¾è½¬æ¢
```python
# åæ€ç‰¹å¾logè½¬æ¢
skewed_features = ['income', 'loan_amount']
for col in skewed_features:
    df_full[col + '_log'] = np.log1p(df_full[col])
    
    # å‰åå¯¹æ¯”
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    df_full[col].hist(bins=30, ax=axes[0], edgecolor='black')
    axes[0].set_title(f'{col} - Original')
    df_full[col + '_log'].hist(bins=30, ax=axes[1], edgecolor='black')
    axes[1].set_title(f'{col} - Log Transformed')
    plt.tight_layout()
    plt.show()
```

---

## 6. ç‰¹å¾å·¥ç¨‹

### 6.1 ç¼–ç 
```python
# One-Hot Encodingï¼ˆä½åŸºæ•°ï¼‰
low_cardinality = [col for col in categorical_cols 
                   if df_full[col].nunique() <= 5]
df_full = pd.get_dummies(df_full, columns=low_cardinality, prefix=low_cardinality)

# Target Encodingï¼ˆé«˜åŸºæ•°ï¼‰
from category_encoders import TargetEncoder
high_cardinality = [col for col in categorical_cols 
                    if df_full[col].nunique() > 10]
te = TargetEncoder(cols=high_cardinality)
df_full[high_cardinality] = te.fit_transform(df_full[high_cardinality], df_full['target'])
```

### 6.2 äº¤äº’ç‰¹å¾
```python
# åŸºäºé¢†åŸŸçŸ¥è¯†åˆ›å»º
df_full['debt_to_income'] = df_full['debt'] / (df_full['income'] + 1)
df_full['credit_utilization'] = df_full['credit_used'] / (df_full['credit_limit'] + 1)

# è§£é‡Š
print("åˆ›å»ºäº¤äº’ç‰¹å¾ï¼š")
print("- debt_to_income: è¡¡é‡è¿˜æ¬¾èƒ½åŠ›")
print("- credit_utilization: ä¿¡ç”¨ä½¿ç”¨ç‡")
```

### 6.3 åˆ†ç®±
```python
# å¹´é¾„åˆ†ç®±
df_full['age_group'] = pd.cut(df_full['age'], 
                               bins=[0, 25, 35, 50, 100],
                               labels=['Young', 'Adult', 'Middle', 'Senior'])
```

---

## 7. Biasæ£€æµ‹ä¸ç¼“è§£

### 7.1 Biasé‡åŒ–
```python
# è®¡ç®—ä¸åŒç¾¤ä½“çš„ç›®æ ‡å˜é‡åˆ†å¸ƒ
bias_analysis = df_full.groupby('gender')['target'].value_counts(normalize=True).unstack()
print(bias_analysis)

# å¯è§†åŒ–
bias_analysis.plot(kind='bar', figsize=(10, 6))
plt.title('Target Distribution by Gender')
plt.ylabel('Proportion')
plt.show()
```

### 7.2 Biasç¼“è§£
```python
# æ–¹æ³•1ï¼šé‡é‡‡æ ·
from imblearn.over_sampling import RandomOverSampler

# åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
X = df_full.drop('target', axis=1)
y = df_full['target']

# å¯¹ä¸åŒç¾¤ä½“é‡é‡‡æ ·
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

print(f"Before: {len(y)}")
print(f"After: {len(y_resampled)}")

# æ–¹æ³•2ï¼šå…¬å¹³æ€§çº¦æŸ
# [å¯é€‰ï¼šä½¿ç”¨fairlearnåº“]
```

---

## 8. æ¨¡å‹å¯¹æ¯”å®éªŒ

### 8.1 æ•°æ®åˆ†å‰²
```python
# Minimalç‰ˆæœ¬
X_minimal = df_minimal.select_dtypes(include=[np.number])
y_minimal = X_minimal.pop('target')
X_train_min, X_test_min, y_train_min, y_test_min = train_test_split(
    X_minimal, y_minimal, test_size=0.2, random_state=42)

# Fullç‰ˆæœ¬
X_full = df_full.select_dtypes(include=[np.number])
y_full = X_full.pop('target')
X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
    X_full, y_full, test_size=0.2, random_state=42)
```

### 8.2 æ¨¡å‹è®­ç»ƒ
```python
# Logistic Regressionï¼ˆç®€å•æ¨¡å‹ï¼‰
from sklearn.linear_model import LogisticRegression

# Minimalæ•°æ®
lr_minimal = LogisticRegression(random_state=42, max_iter=1000)
lr_minimal.fit(X_train_min, y_train_min)
y_pred_min = lr_minimal.predict(X_test_min)

# Fullæ•°æ®
lr_full = LogisticRegression(random_state=42, max_iter=1000)
lr_full.fit(X_train_full, y_train_full)
y_pred_full = lr_full.predict(X_test_full)
```

### 8.3 æ€§èƒ½å¯¹æ¯”
```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# è®¡ç®—æŒ‡æ ‡
metrics_minimal = {
    'Accuracy': accuracy_score(y_test_min, y_pred_min),
    'Precision': precision_score(y_test_min, y_pred_min, average='weighted'),
    'Recall': recall_score(y_test_min, y_pred_min, average='weighted'),
    'F1': f1_score(y_test_min, y_pred_min, average='weighted'),
    'AUC': roc_auc_score(y_test_min, lr_minimal.predict_proba(X_test_min), multi_class='ovr')
}

metrics_full = {
    'Accuracy': accuracy_score(y_test_full, y_pred_full),
    'Precision': precision_score(y_test_full, y_pred_full, average='weighted'),
    'Recall': recall_score(y_test_full, y_pred_full, average='weighted'),
    'F1': f1_score(y_test_full, y_pred_full, average='weighted'),
    'AUC': roc_auc_score(y_test_full, lr_full.predict_proba(X_test_full), multi_class='ovr')
}

# å¯¹æ¯”è¡¨æ ¼
comparison_df = pd.DataFrame({
    'Minimal Processing': metrics_minimal,
    'Full Preparation': metrics_full,
    'Improvement': [metrics_full[k] - metrics_minimal[k] for k in metrics_minimal.keys()]
})
print(comparison_df)

# å¯è§†åŒ–
comparison_df[['Minimal Processing', 'Full Preparation']].plot(kind='bar', figsize=(10, 6))
plt.title('Model Performance Comparison')
plt.ylabel('Score')
plt.xticks(rotation=0)
plt.legend(loc='lower right')
plt.show()
```

### 8.4 ROCæ›²çº¿å¯¹æ¯”
```python
from sklearn.metrics import roc_curve, auc

# è®¡ç®—ROC
fpr_min, tpr_min, _ = roc_curve(y_test_min, lr_minimal.predict_proba(X_test_min)[:, 1])
fpr_full, tpr_full, _ = roc_curve(y_test_full, lr_full.predict_proba(X_test_full)[:, 1])

# ç»˜å›¾
plt.figure(figsize=(10, 6))
plt.plot(fpr_min, tpr_min, label=f'Minimal (AUC={metrics_minimal["AUC"]:.3f})')
plt.plot(fpr_full, tpr_full, label=f'Full Prep (AUC={metrics_full["AUC"]:.3f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.show()
```

### 8.5 ç‰¹å¾é‡è¦æ€§
```python
# è·å–ç³»æ•°
feature_importance = pd.DataFrame({
    'Feature': X_train_full.columns,
    'Coefficient': lr_full.coef_[0]
}).sort_values('Coefficient', key=abs, ascending=False)

# å¯è§†åŒ–Top 15
top_features = feature_importance.head(15)
plt.figure(figsize=(10, 6))
plt.barh(top_features['Feature'], top_features['Coefficient'])
plt.xlabel('Coefficient')
plt.title('Top 15 Feature Importance')
plt.gca().invert_yaxis()
plt.show()
```

### 8.6 æ··æ·†çŸ©é˜µ
```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Minimal
cm_min = confusion_matrix(y_test_min, y_pred_min)
# Full
cm_full = confusion_matrix(y_test_full, y_pred_full)

# å¯è§†åŒ–
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

sns.heatmap(cm_min, annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title('Minimal Processing')
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')

sns.heatmap(cm_full, annot=True, fmt='d', cmap='Greens', ax=axes[1])
axes[1].set_title('Full Preparation')
axes[1].set_xlabel('Predicted')
axes[1].set_ylabel('Actual')

plt.tight_layout()
plt.show()
```

---

## 9. ç»“æœåˆ†æä¸æ´å¯Ÿ

### 9.1 æ€§èƒ½æ”¹è¿›åˆ†æ
```markdown
**å…³é”®å‘ç°ï¼š**

1. **æ•´ä½“æ€§èƒ½æå‡**
   - å‡†ç¡®ç‡æå‡ï¼š+X%
   - AUCæå‡ï¼š+Y
   - ä¸»è¦åŸå› ï¼š[å…·ä½“åˆ†æ]

2. **å“ªäº›æ•°æ®å‡†å¤‡æ­¥éª¤æœ€æœ‰å½±å“ï¼Ÿ**
   - ç¼ºå¤±å€¼å¤„ç†ï¼š[å½±å“]
   - ç¦»ç¾¤å€¼å¤„ç†ï¼š[å½±å“]
   - ç‰¹å¾å·¥ç¨‹ï¼š[å½±å“]
   - è¯æ®ï¼šé€šè¿‡æ¶ˆèå®éªŒéªŒè¯

3. **æ„å¤–å‘ç°**
   - å‘ç°1ï¼š[æè¿°+è§£é‡Š]
   - å‘ç°2ï¼š[æè¿°+è§£é‡Š]
```

### 9.2 é”™è¯¯æ¡ˆä¾‹åˆ†æ
```python
# æ‰¾å‡ºé¢„æµ‹é”™è¯¯çš„æ ·æœ¬
errors = X_test_full[y_test_full != y_pred_full]
print(f"é”™è¯¯é¢„æµ‹æ•°é‡: {len(errors)}")

# åˆ†æé”™è¯¯æ ·æœ¬çš„ç‰¹å¾
error_analysis = errors.describe()
correct_analysis = X_test_full[y_test_full == y_pred_full].describe()

# å¯¹æ¯”
comparison = pd.concat([error_analysis.loc['mean'], correct_analysis.loc['mean']], axis=1)
comparison.columns = ['Errors', 'Correct']
comparison['Difference'] = comparison['Errors'] - comparison['Correct']
print(comparison.sort_values('Difference', key=abs, ascending=False).head(10))
```

**é”™è¯¯æ¨¡å¼ï¼š**
- æ¨¡å¼1ï¼š[æè¿°]
- æ¨¡å¼2ï¼š[æè¿°]
- æ”¹è¿›æ–¹å‘ï¼š[å»ºè®®]

### 9.3 Fairnessè¯„ä¼°
```python
# ä¸åŒç¾¤ä½“çš„æ€§èƒ½å·®å¼‚
for group in df_full['gender'].unique():
    mask = X_test_full['gender'] == group  # å‡è®¾genderåœ¨ç‰¹å¾ä¸­
    group_acc = accuracy_score(y_test_full[mask], y_pred_full[mask])
    print(f"{group} Accuracy: {group_acc:.3f}")

# Demographic Parity
# [è®¡ç®—å¹¶å¯è§†åŒ–]
```

---

## 10. æ€»ç»“ä¸åæ€

### 10.1 ä¸»è¦è´¡çŒ®
```markdown
1. **æ•°æ®å‡†å¤‡ç­–ç•¥**
   - åˆ›æ–°ç‚¹ï¼š[æè¿°]
   - æ•ˆæœï¼š[é‡åŒ–]

2. **Biasç¼“è§£æ–¹æ³•**
   - æ–¹æ³•ï¼š[æè¿°]
   - æ”¹è¿›ï¼š[é‡åŒ–]

3. **åˆ†ææ´å¯Ÿ**
   - Simpson's Paradoxå‘ç°ï¼š[æè¿°]
   - ä¸šåŠ¡å«ä¹‰ï¼š[è§£é‡Š]
```

### 10.2 å­¦åˆ°çš„æ•™è®­
```markdown
**æˆåŠŸç»éªŒï¼š**
- ç»éªŒ1ï¼š...
- ç»éªŒ2ï¼š...

**æŒ‘æˆ˜ä¸è§£å†³ï¼š**
- æŒ‘æˆ˜1ï¼š... â†’ è§£å†³æ–¹æ¡ˆï¼š...
- æŒ‘æˆ˜2ï¼š... â†’ è§£å†³æ–¹æ¡ˆï¼š...

**å¦‚æœé‡åšï¼š**
- æ”¹è¿›1ï¼š...
- æ”¹è¿›2ï¼š...
```

### 10.3 æœªæ¥æ–¹å‘
```markdown
- æ–¹å‘1ï¼šå°è¯•æ›´é«˜çº§çš„å¡«è¡¥æ–¹æ³•ï¼ˆå¦‚MICEï¼‰
- æ–¹å‘2ï¼šæ·±å…¥åˆ†æç‰¹å®šå­ç¾¤ä½“
- æ–¹å‘3ï¼šçº³å…¥æ›´å¤šé¢†åŸŸçŸ¥è¯†
```

---

## é™„å½•

### A. å®Œæ•´ä»£ç 
[æä¾›å®Œæ•´å¯è¿è¡Œçš„ä»£ç ]

### B. æ•°æ®å­—å…¸
[å®Œæ•´çš„ç‰¹å¾è¯´æ˜]

### C. å‚è€ƒæ–‡çŒ®
[å¼•ç”¨çš„è®ºæ–‡ã€æ–‡æ¡£]
```

---

**ğŸ“ Markdownå†™ä½œè§„èŒƒï¼š**

```markdown
ä¼˜ç§€çš„Markdownåº”è¯¥ï¼š

1. **ç»“æ„æ¸…æ™°**
   - ä½¿ç”¨#æ ‡é¢˜å±‚çº§
   - æ¯ä¸ªsectionæœ‰æ˜ç¡®ç›®çš„
   - é€»è¾‘æµç•…è¿è´¯

2. **ä»£ç å—è§„èŒƒ**
   - æ¯ä¸ªä»£ç å—éƒ½æœ‰æ³¨é‡Š
   - è¾“å‡ºç»“æœç´§è·Ÿä»£ç 
   - é‡è¦è¾“å‡ºç”¨Markdownè¡¨æ ¼å±•ç¤º

3. **å¯è§†åŒ–æ ‡æ³¨**
   - æ¯ä¸ªå›¾éƒ½æœ‰æ ‡é¢˜
   - å›¾åéƒ½æœ‰æ–‡å­—è§£é‡Š
   - æŒ‡å‡ºå…³é”®å‘ç°

4. **å†³ç­–è®°å½•**
   - ç”¨è¡¨æ ¼è®°å½•é‡è¦å†³ç­–
   - è¯´æ˜ç†ç”±å’Œè¯æ®
   - å¯¹æ¯”ä¸åŒé€‰æ‹©

5. **é¿å…å†—ä½™**
   - ä¸è¦é‡å¤ä»£ç 
   - ä¸è¦è¿‡åº¦å¯è§†åŒ–
   - ä¿æŒç®€æ´æœ‰åŠ›

âš ï¸ å¸¸è§é”™è¯¯ï¼š
- âŒ ä»£ç æ²¡æœ‰æ³¨é‡Š
- âŒ å›¾è¡¨æ²¡æœ‰è§£é‡Š
- âŒ å†³ç­–æ²¡æœ‰ç†ç”±
- âŒ ç»“æ„æ··ä¹±è·³è·ƒ
- âŒ è¾“å‡ºå¤ªå¤šä¸é‡è¦ä¿¡æ¯
```

---

## **é˜¶æ®µ7ï¼šè§†é¢‘åˆ¶ä½œï¼ˆWeek 4ï¼ŒDay 1-5ï¼‰**

### ç›®æ ‡ï¼šåšä¸€ä¸ª"TED Talkçº§"çš„æ¼”ç¤º

**ğŸ¬ è§†é¢‘ç»“æ„ï¼ˆ12åˆ†é’Ÿï¼Œä¸¥æ ¼åˆ†é…ï¼‰ï¼š**

```
æ—¶é—´åˆ†é…ï¼ˆæ€»è®¡12åˆ†é’Ÿï¼‰ï¼š

00:00 - 01:00  å¼€åœºä»‹ç»ï¼ˆ1åˆ†é’Ÿï¼‰
01:00 - 02:30  æ•°æ®é›†èƒŒæ™¯ä¸é—®é¢˜ï¼ˆ1.5åˆ†é’Ÿï¼‰
02:30 - 04:30  EDAå…³é”®å‘ç°ï¼ˆ2åˆ†é’Ÿï¼‰
04:30 - 06:30  æ•°æ®æ¸…æ´—ä¸è½¬æ¢ï¼ˆ2åˆ†é’Ÿï¼‰
06:30 - 08:00  Biasåˆ†æï¼ˆ1.5åˆ†é’Ÿï¼‰
08:00 - 10:00  æ¨¡å‹å¯¹æ¯”å®éªŒï¼ˆ2åˆ†é’Ÿï¼‰
10:00 - 11:30  å…³é”®æ´å¯Ÿä¸ç»“è®ºï¼ˆ1.5åˆ†é’Ÿï¼‰
11:30 - 12:00  å›¢é˜Ÿè´¡çŒ®ä¸Q&Aï¼ˆ0.5åˆ†é’Ÿï¼‰

âš ï¸ ä¸¥æ ¼æ§åˆ¶æ—¶é—´ï¼è¶…è¿‡12åˆ†é’Ÿä¼šè¢«æˆªæ–­ï¼
```

**ğŸ“¹ è§†é¢‘åˆ¶ä½œè¦æ±‚ï¼š**

```markdown
æŠ€æœ¯è¦æ±‚ï¼š
1. **å½•åˆ¶å·¥å…·**
   - Zoomï¼ˆæ¨èï¼‰
   - Microsoft Teams
   - OBS Studioï¼ˆé«˜çº§ï¼‰

2. **è§†é¢‘è´¨é‡**
   - åˆ†è¾¨ç‡ï¼šè‡³å°‘1080p
   - å£°éŸ³æ¸…æ™°ï¼ˆç”¨è€³æœºéº¦å…‹é£ï¼‰
   - å…‰çº¿å……è¶³ï¼ˆè„¸éƒ¨å¯è§ï¼‰
   - èƒŒæ™¯æ•´æ´ä¸“ä¸š

3. **å±•ç¤ºå½¢å¼**
   - ç”»ä¸­ç”»ï¼šäººåƒ+PPT
   - æ‰€æœ‰äººéƒ½è¦å‡ºé•œ
   - åˆ‡æ¢æµç•…è‡ªç„¶

4. **PPTè®¾è®¡**
   - ç®€æ´æ¸…æ™°ï¼ˆæ¯é¡µ<50å­—ï¼‰
   - å¤§å­—ä½“ï¼ˆæ ‡é¢˜â‰¥32ptï¼‰
   - é«˜å¯¹æ¯”åº¦é…è‰²
   - å…³é”®æ•°å­—çªå‡ºæ˜¾ç¤º
   - å›¾è¡¨æ¸…æ™°å¯è¯»

å†…å®¹è¦æ±‚ï¼š
1. **å¼€åœºï¼ˆ1åˆ†é’Ÿï¼‰**
   - è‡ªæˆ‘ä»‹ç»ï¼ˆæ¯äºº5-10ç§’ï¼‰
   - é¡¹ç›®èƒŒæ™¯ç®€ä»‹
   - æ ¸å¿ƒé—®é¢˜é™ˆè¿°
   
   ç¤ºä¾‹è„šæœ¬ï¼š
   "å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯XXã€‚ä»Šå¤©æˆ‘ä»¬è¦å±•ç¤ºçš„æ˜¯å…³äº[æ•°æ®é›†åç§°]çš„æ•°æ®å‡†å¤‡åˆ†æã€‚
   è¿™ä¸ªæ•°æ®é›†æ¶‰åŠ[é¢†åŸŸ]ï¼ŒåŒ…å«[X]è¡Œæ•°æ®å’Œ[Y]ä¸ªç‰¹å¾ã€‚
   æˆ‘ä»¬çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼š[é—®é¢˜é™ˆè¿°]ã€‚
   æˆ‘ä»¬å°†å±•ç¤ºæ•°æ®å‡†å¤‡å¦‚ä½•æ˜¾è‘—å½±å“æ¨¡å‹æ€§èƒ½ã€‚"

2. **æ•°æ®æ¢ç´¢ï¼ˆ3.5åˆ†é’Ÿï¼‰**
   - ç”¨1-2ä¸ªæœ€éœ‡æ’¼çš„å¯è§†åŒ–
   - è®²æ¸…æ¥šæœ€é‡è¦çš„å‘ç°
   - å¼ºè°ƒé—®é¢˜ï¼ˆç¼ºå¤±ã€ç¦»ç¾¤ã€åå·®ï¼‰
   
   å…³é”®ç‚¹ï¼š
   - ä¸è¦å±•ç¤ºæ‰€æœ‰å›¾ï¼åªå±•ç¤ºæœ€æœ‰è¯´æœåŠ›çš„
   - æ¯ä¸ªå›¾éƒ½è¦æœ‰"æ•…äº‹"
   - ç”¨æ•°å­—è¯´è¯ï¼ˆ"30%çš„æ•°æ®æœ‰ç¼ºå¤±"ï¼‰

3. **æ•°æ®å‡†å¤‡ï¼ˆ3.5åˆ†é’Ÿï¼‰**
   - Before/Afterå¯¹æ¯”è¦éœ‡æ’¼
   - æ¯ä¸ªå†³ç­–éƒ½è¦justify
   - å±•ç¤ºå¤„ç†è¿‡ç¨‹çš„å¯è§†åŒ–
   
   è„šæœ¬ç¤ºä¾‹ï¼š
   "æˆ‘ä»¬å‘ç°[ç‰¹å¾å]æœ‰ä¸¥é‡åæ€ã€‚å·¦å›¾æ˜¯åŸå§‹åˆ†å¸ƒï¼Œå³å›¾æ˜¯logè½¬æ¢åã€‚
   å¯ä»¥çœ‹åˆ°è½¬æ¢åæ›´æ¥è¿‘æ­£æ€åˆ†å¸ƒï¼Œè¿™å°†å¸®åŠ©çº¿æ€§æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ ã€‚"

4. **æ¨¡å‹å¯¹æ¯”ï¼ˆ2åˆ†é’Ÿï¼‰**
   - ç”¨æ¸…æ™°çš„å¯¹æ¯”å›¾
   - å¼ºè°ƒæ€§èƒ½æå‡
   - è§£é‡Šä¸ºä»€ä¹ˆæå‡
   
   é‡ç‚¹å¼ºè°ƒï¼š
   - "æ•°æ®å‡†å¤‡ä½¿å‡†ç¡®ç‡æå‡äº†X%"
   - "æœ€é‡è¦çš„æ”¹è¿›æ¥è‡ª[å…·ä½“æ­¥éª¤]"
   - "è¿™è¯æ˜äº†[æ•°æ®å‡†å¤‡åŸåˆ™]çš„é‡è¦æ€§"

5. **æ´å¯Ÿä¸æ€»ç»“ï¼ˆ2åˆ†é’Ÿï¼‰**
   - 3ä¸ªæœ€é‡è¦çš„å‘ç°
   - å­¦åˆ°çš„æ•™è®­
   - å›¢é˜Ÿåˆ†å·¥
   
   è„šæœ¬ç¤ºä¾‹ï¼š
   "é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä»¬å¾—å‡ºä¸‰ä¸ªå…³é”®æ´å¯Ÿï¼š
   ç¬¬ä¸€ï¼Œ[æ´å¯Ÿ1]ã€‚ç¬¬äºŒï¼Œ[æ´å¯Ÿ2]ã€‚ç¬¬ä¸‰ï¼Œ[æ´å¯Ÿ3]ã€‚
   æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬è¯æ˜äº†é«˜è´¨é‡çš„æ•°æ®å‡†å¤‡æ¯”å¤æ‚çš„æ¨¡å‹æ›´é‡è¦ã€‚"

è¡¨è¾¾æŠ€å·§ï¼š
1. **è¯­é€Ÿæ§åˆ¶**
   - ä¸è¦å¤ªå¿«ï¼ˆ120-150è¯/åˆ†é’Ÿï¼‰
   - å…³é”®ç‚¹è¦æ”¾æ…¢å¼ºè°ƒ
   - æ•°å­—è¦æ¸…æ¥šå¿µå‡º

2. **è‚¢ä½“è¯­è¨€**
   - æ‰‹åŠ¿æŒ‡å‘PPTå…³é”®ç‚¹
   - çœ¼ç¥çœ‹é•œå¤´ï¼ˆä¸è¦åªçœ‹å±å¹•ï¼‰
   - è¡¨æƒ…è‡ªç„¶å¾®ç¬‘

3. **è¿‡æ¸¡æµç•…**
   - "æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹..."
   - "æ›´æœ‰æ„æ€çš„æ˜¯..."
   - "è¿™å¯¼è‡´äº†ä¸€ä¸ªé‡è¦å‘ç°..."

4. **å›¢é˜Ÿåä½œ**
   - æå‰æ’ç»ƒ3-5æ¬¡
   - æ¯äººè´Ÿè´£è‡ªå·±æ“…é•¿çš„éƒ¨åˆ†
   - äº¤æ¥è¦è‡ªç„¶ï¼ˆ"ç°åœ¨è¯·XXç»§ç»­è®²è§£..."ï¼‰

âš ï¸ é¿å…çš„é”™è¯¯ï¼š
- âŒ è¯»PPTï¼ˆè¦conversationalï¼‰
- âŒ è¿‡åº¦æŠ€æœ¯æœ¯è¯­
- âŒ æ²¡æœ‰eye contact
- âŒ è¯­é€Ÿå¤ªå¿«
- âŒ èƒŒæ™¯å™ªéŸ³
- âŒ æ—¶é—´è¶…æ—¶
```

---

## ğŸ¯ é«˜åˆ†æ£€æŸ¥æ¸…å•

### **æäº¤å‰æœ€ç»ˆæ£€æŸ¥ï¼ˆå¿…åšï¼ï¼‰**

```markdown
Jupyter Notebookæ£€æŸ¥ï¼š
â–¡ æ‰€æœ‰ä»£ç éƒ½èƒ½è¿è¡Œ
â–¡ æ²¡æœ‰é”™è¯¯æˆ–è­¦å‘Š
â–¡ æ‰€æœ‰å›¾è¡¨éƒ½èƒ½æ­£å¸¸æ˜¾ç¤º
â–¡ Markdownè§£é‡Šæ¸…æ™°å®Œæ•´
â–¡ æ¯ä¸ªå†³ç­–éƒ½æœ‰ç†ç”±
â–¡ ä»£ç æœ‰è¯¦ç»†æ³¨é‡Š
â–¡ ç»“æ„æ¸…æ™°æœ‰é€»è¾‘
â–¡ æ–‡ä»¶å¤§å°<100MB
â–¡ æ–‡ä»¶ååŒ…å«ç»„å·

è§†é¢‘æ£€æŸ¥ï¼š
â–¡ æ—¶é•¿â‰¤12åˆ†é’Ÿ
â–¡ æ‰€æœ‰æˆå‘˜éƒ½å‡ºé•œ
â–¡ å£°éŸ³æ¸…æ™°æ— æ‚éŸ³
â–¡ PPTæ¸…æ™°å¯è¯»
â–¡ YouTubeé“¾æ¥å¯è®¿é—®
â–¡ è§†é¢‘è®¾ä¸ºå…¬å¼€
â–¡ æ ‡é¢˜åŒ…å«ç»„å·
â–¡ å­—å¹•å‡†ç¡®ï¼ˆå¯é€‰ä½†æ¨èï¼‰

å†…å®¹æ£€æŸ¥ï¼š
â–¡ åŒ…å«æ‰€æœ‰4ä¸ªå­¦ä¹ ç›®æ ‡
â–¡ å±•ç¤ºäº†Minimal vs Fullå¯¹æ¯”
â–¡ è¯†åˆ«äº†analytical fallacies
â–¡ æ£€æµ‹å¹¶ç¼“è§£äº†bias
â–¡ åªç”¨äº†ç®€å•æ¨¡å‹
â–¡ å¼ºè°ƒäº†æ•°æ®å‡†å¤‡è€Œéå‡†ç¡®ç‡
â–¡ æœ‰åŸåˆ›æ´å¯Ÿ
â–¡ å¼•ç”¨äº†æ•°æ®æ¥æº

å›¢é˜Ÿåä½œï¼š
â–¡ åˆ†å·¥æ˜ç¡®è®°å½•
â–¡ æ¯äººè´¡çŒ®æ¸…æ™°
â–¡ å‡†å¤‡å¥½peer evaluation
â–¡ æ‰€æœ‰äººéƒ½ç†è§£å…¨éƒ¨å†…å®¹

æäº¤ï¼š
â–¡ åœ¨deadlineå‰æäº¤
â–¡ YouTubeé“¾æ¥æœ‰æ•ˆ
â–¡ .ipynbæ ¼å¼æ­£ç¡®
â–¡ ç»„é•¿ç¡®è®¤æäº¤æˆåŠŸ
```

---

## ğŸ“… è¯¦ç»†æ—¶é—´è§„åˆ’ï¼ˆ4å‘¨ï¼‰

### Week 1ï¼ˆæ•°æ®é€‰æ‹© + åˆæ­¥EDAï¼‰
```
Day 1-2: é€‰æ‹©æ•°æ®é›†
- æµè§ˆæ¨èç½‘ç«™
- ç­›é€‰å€™é€‰æ•°æ®é›†
- ç»„å†…æŠ•ç¥¨å†³å®š
- ä¸‹è½½å¹¶åˆæ­¥æŸ¥çœ‹

Day 3-4: æ•°æ®Profiling
- åŸºç¡€ç»Ÿè®¡
- ç¼ºå¤±å€¼åˆ†æ
- åˆ†å¸ƒåˆ†æ
- ç±»å‹æ£€æŸ¥

Day 5-7: æ·±åº¦EDA
- ç›¸å…³æ€§åˆ†æ
- ç¦»ç¾¤å€¼æ£€æµ‹
- Biasæ£€æµ‹
- QQ Plot
- Simpson's Paradoxæ¢ç´¢
```

### Week 2ï¼ˆæ•°æ®æ¸…æ´— + ç‰¹å¾å·¥ç¨‹ï¼‰
```
Day 1-2: æ•°æ®æ¸…æ´—
- ç¼ºå¤±å€¼å¤„ç†
- ç¦»ç¾¤å€¼å¤„ç†
- é‡å¤å€¼æ£€æŸ¥
- æ•°æ®éªŒè¯

Day 3-4: ç‰¹å¾å·¥ç¨‹
- ç¼–ç 
- ç¼©æ”¾
- è½¬æ¢
- äº¤äº’ç‰¹å¾
- åˆ†ç®±

Day 5-7: åˆ›å»ºå¯¹æ¯”ç‰ˆæœ¬
- Minimalç‰ˆæœ¬
- Fullç‰ˆæœ¬
- è®°å½•æ‰€æœ‰å†³ç­–
- éªŒè¯æ•°æ®è´¨é‡
```

### Week 3ï¼ˆå»ºæ¨¡ + Notebookæ’°å†™ï¼‰
```
Day 1-3: æ¨¡å‹å®éªŒ
- è®­ç»ƒç®€å•æ¨¡å‹
- æ€§èƒ½å¯¹æ¯”
- ç‰¹å¾é‡è¦æ€§
- é”™è¯¯åˆ†æ
- Fairnessè¯„ä¼°

Day 4-7: Notebookæ’°å†™
- æ•´ç†æ‰€æœ‰ä»£ç 
- æ·»åŠ Markdownè§£é‡Š
- åˆ›å»ºå¯è§†åŒ–
- å®Œå–„æ–‡æ¡£
- å†…éƒ¨review
```

### Week 4ï¼ˆè§†é¢‘åˆ¶ä½œ + æäº¤ï¼‰
```
Day 1-2: PPTåˆ¶ä½œ
- è®¾è®¡slides
- ç²¾ç®€å†…å®¹
- ç¾åŒ–å›¾è¡¨
- æ’ç»ƒè„šæœ¬

Day 3-4: è§†é¢‘å½•åˆ¶
- ç¬¬ä¸€æ¬¡å½•åˆ¶
- Reviewå¹¶æ”¹è¿›
- ç¬¬äºŒæ¬¡å½•åˆ¶
- æœ€ç»ˆç‰ˆæœ¬

Day 5: æäº¤
- ä¸Šä¼ YouTube
- æ£€æŸ¥é“¾æ¥
- æäº¤Notebook
- ç¡®è®¤æäº¤æˆåŠŸ
- å‡†å¤‡peer evaluation
```

---

## ğŸ’ åŠ åˆ†æŠ€å·§ï¼ˆä»80åˆ†åˆ°95åˆ†+ï¼‰

### 1. æ•°æ®é›†é€‰æ‹©åŠ åˆ†é¡¹
```
âœ¨ é€‰ä¸€ä¸ªæœ‰ç¤¾ä¼šæ„ä¹‰çš„æ•°æ®é›†
   â†’ ä¾‹ï¼šåŒ»ç–—å…¬å¹³ã€è´·æ¬¾æ­§è§†ã€å°±ä¸šbias
   
âœ¨ é€‰ä¸€ä¸ªæœ‰æ˜æ˜¾ethical concernsçš„
   â†’ å®¹æ˜“å±•ç¤ºbiasåˆ†ææ·±åº¦
   
âœ¨ é€‰ä¸€ä¸ªæœ‰æ—¶é—´ç»´åº¦çš„
   â†’ å¯ä»¥åšæ—¶é—´åºåˆ—åˆ†æ
```

### 2. åˆ†ææ·±åº¦åŠ åˆ†é¡¹
```
âœ¨ æ‰¾åˆ°çœŸå®çš„Simpson's Paradoxæ¡ˆä¾‹
   â†’ è¿™æ˜¯å¾ˆå°‘æœ‰äººèƒ½åšåˆ°çš„
   
âœ¨ ç”¨ç»Ÿè®¡æ£€éªŒæ”¯æŒç»“è®º
   â†’ t-test, chi-square, ANOVA
   
âœ¨ åšæ¶ˆèå®éªŒï¼ˆablation studyï¼‰
   â†’ é€ä¸ªç§»é™¤æ•°æ®å‡†å¤‡æ­¥éª¤ï¼Œçœ‹å½±å“
   
âœ¨ åˆ†ææ¨¡å‹çš„decision boundary
   â†’ å¯è§†åŒ–æ¨¡å‹å­¦åˆ°äº†ä»€ä¹ˆ
```

### 3. å¯è§†åŒ–åŠ åˆ†é¡¹
```
âœ¨ äº¤äº’å¼å¯è§†åŒ–ï¼ˆPlotlyï¼‰
   â†’ ä½†notebooké‡Œè¦èƒ½æ­£å¸¸æ˜¾ç¤º
   
âœ¨ åˆ›æ–°çš„å¯è§†åŒ–æ–¹å¼
   â†’ ä¸åªæ˜¯bar/line chart
   â†’ Sankey diagram, TreeMapç­‰
   
âœ¨ Before/Afterå¯¹æ¯”åŠ¨ç”»
   â†’ ç”¨matplotlib animation
```

### 4. æ´å¯Ÿæ·±åº¦åŠ åˆ†é¡¹
```
âœ¨ è¿æ¥åˆ°ç°å®ä¸–ç•Œå½±å“
   â†’ "è¿™ä¸ªbiasä¼šå¯¼è‡´XXç¾¤ä½“è¢«æ‹’è´·"
   
âœ¨ æå‡ºå¯è¡Œçš„æ”¹è¿›å»ºè®®
   â†’ "å»ºè®®æ”¶é›†XXæ•°æ®æ¥å‡å°‘åå·®"
   
âœ¨ è®¨è®ºethical implications
   â†’ "è™½ç„¶æ€§èƒ½æå‡äº†ï¼Œä½†å…¬å¹³æ€§ä¸‹é™äº†"
   
âœ¨ å¼•ç”¨å­¦æœ¯æ–‡çŒ®
   â†’ æ”¯æŒä½ çš„æ•°æ®å‡†å¤‡å†³ç­–
```

### 5. æ¼”ç¤ºæŠ€å·§åŠ åˆ†é¡¹
```
âœ¨ è®²ä¸€ä¸ªå®Œæ•´çš„æ•…äº‹
   â†’ æœ‰èµ·æ‰¿è½¬åˆï¼Œä¸æ˜¯ç½—åˆ—ç»“æœ
   
âœ¨ ç”¨ç±»æ¯”å¸®åŠ©ç†è§£
   â†’ "Simpson's Paradoxå°±åƒ..."
   
âœ¨ å±•ç¤ºå¤±è´¥æ¡ˆä¾‹
   â†’ "æˆ‘ä»¬æœ€åˆå°è¯•äº†XXï¼Œä½†å¤±è´¥äº†ï¼Œå› ä¸º..."
   
âœ¨ æé—®äº’åŠ¨ï¼ˆå¦‚æœæ˜¯liveï¼‰
   â†’ "å¤§å®¶è§‰å¾—è¿™ä¸ªç¦»ç¾¤å€¼åº”è¯¥ä¿ç•™è¿˜æ˜¯åˆ é™¤ï¼Ÿ"
```

---

## âš ï¸ å¸¸è§é™·é˜±ä¸é¿å…æ–¹æ³•

### é™·é˜±1ï¼šè¿½æ±‚æ¨¡å‹å‡†ç¡®ç‡
```
âŒ é”™è¯¯åšæ³•ï¼š
"æˆ‘ä»¬è°ƒå‚åˆ°äº†98%å‡†ç¡®ç‡ï¼"

âœ… æ­£ç¡®åšæ³•ï¼š
"é€šè¿‡åˆç†çš„æ•°æ®å‡†å¤‡ï¼Œæˆ‘ä»¬ä½¿å‡†ç¡®ç‡ä»75%æå‡åˆ°82%ã€‚
è¿™7%çš„æå‡ä¸»è¦æ¥è‡ªäº[å…·ä½“çš„æ•°æ®å‡†å¤‡æ­¥éª¤]ï¼Œ
è¯æ˜äº†[æ•°æ®å‡†å¤‡åŸåˆ™]çš„é‡è¦æ€§ã€‚"
```

### é™·é˜±2ï¼šä½¿ç”¨å¤æ‚æ¨¡å‹
```
âŒ é”™è¯¯åšæ³•ï¼š
ä½¿ç”¨XGBoost, Random Forestç­‰

âœ… æ­£ç¡®åšæ³•ï¼š
åªä½¿ç”¨Logistic Regression, Linear Regression, Decision Tree
æ˜ç¡®è¯´æ˜ï¼š"æˆ‘ä»¬åˆ»æ„ä½¿ç”¨ç®€å•æ¨¡å‹ï¼Œå› ä¸ºé‡ç‚¹æ˜¯æ•°æ®è€Œéç®—æ³•"
```

### é™·é˜±3ï¼šæ²¡æœ‰justifyå†³ç­–
```
âŒ é”™è¯¯åšæ³•ï¼š
"æˆ‘ä»¬ç”¨ä¸­ä½æ•°å¡«è¡¥äº†ç¼ºå¤±å€¼"

âœ… æ­£ç¡®åšæ³•ï¼š
"æˆ‘ä»¬ç”¨ä¸­ä½æ•°è€Œéå‡å€¼å¡«è¡¥ç¼ºå¤±å€¼ï¼ŒåŸå› æ˜¯ï¼š
1. æ•°æ®æœ‰ç¦»ç¾¤å€¼ï¼Œä¸­ä½æ•°æ›´é²æ£’
2. ç‰¹å¾åˆ†å¸ƒåæ€ï¼Œä¸­ä½æ•°æ›´èƒ½ä»£è¡¨ä¸­å¿ƒè¶‹åŠ¿
3. å¯¹æ¯”å®éªŒæ˜¾ç¤ºä¸­ä½æ•°å¡«è¡¥æ•ˆæœæ›´å¥½ï¼ˆAUCæå‡0.03ï¼‰"
```

### é™·é˜±4ï¼šå¿½ç•¥biasåˆ†æ
```
âŒ é”™è¯¯åšæ³•ï¼š
åªåšæŠ€æœ¯åˆ†æï¼Œä¸è°ˆä¼¦ç†

âœ… æ­£ç¡®åšæ³•ï¼š
ä¸“é—¨ä¸€ä¸ªsectionåˆ†æbias
å±•ç¤ºä¸åŒç¾¤ä½“çš„å·®å¼‚
è®¨è®ºå…¬å¹³æ€§trade-off
æå‡ºç¼“è§£ç­–ç•¥
```

### é™·é˜±5ï¼šPPTè¿‡äºå¯†é›†
```
âŒ é”™è¯¯åšæ³•ï¼š
ä¸€é¡µPPTæ”¾3ä¸ªå›¾+å¤§æ®µæ–‡å­—

âœ… æ­£ç¡®åšæ³•ï¼š
ä¸€é¡µPPTä¸€ä¸ªé‡ç‚¹
å¤§å­—ä½“å¤§å›¾è¡¨
ç”¨å£å¤´è§£é‡Šç»†èŠ‚
```

### é™·é˜±6ï¼šæ—¶é—´åˆ†é…ä¸å½“
```
âŒ é”™è¯¯åšæ³•ï¼š
å‰8åˆ†é’Ÿä»‹ç»æ•°æ®ï¼Œå4åˆ†é’ŸåŒ†å¿™è®²æ¨¡å‹

âœ… æ­£ç¡®åšæ³•ï¼š
ä¸¥æ ¼æŒ‰ç…§æ—¶é—´åˆ†é…
æ¯ä¸ªéƒ¨åˆ†éƒ½é‡è¦
æå‰æ’ç»ƒè®¡æ—¶
```

### é™·é˜±7ï¼šåˆ†å·¥ä¸æ¸…
```
âŒ é”™è¯¯åšæ³•ï¼š
peer evaluationæ—¶è¯´ä¸æ¸…è°åšäº†ä»€ä¹ˆ

âœ… æ­£ç¡®åšæ³•ï¼š
åœ¨notebookå’Œè§†é¢‘é‡Œæ˜ç¡®æ ‡æ³¨
"è¿™éƒ¨åˆ†ç”±XXå®Œæˆ"
ä¿ç•™å·¥ä½œæ—¥å¿—
```

---

## ğŸ† æ ‡æ†ç¤ºä¾‹ï¼ˆæƒ³è±¡ä¸­çš„æ»¡åˆ†ä½œä¸šï¼‰

### é¡¹ç›®ï¼šHealthcare Bias in Diabetes Prediction

**ä¸ºä»€ä¹ˆæ˜¯æ»¡åˆ†ï¼š**

1. **æ•°æ®é›†é€‰æ‹©ï¼ˆ10/10ï¼‰**
   - åŒ»ç–—æ•°æ®ï¼Œæœ‰ç¤¾ä¼šæ„ä¹‰
   - åŒ…å«ç§æ—ã€æ€§åˆ«ç­‰æ•æ„Ÿç‰¹å¾
   - æ˜æ˜¾çš„ç±»åˆ«ä¸å¹³è¡¡ï¼ˆç³–å°¿ç—…æ‚£è€…<10%ï¼‰
   - æœ‰ç¼ºå¤±å€¼ã€ç¦»ç¾¤å€¼ç­‰é—®é¢˜

2. **EDAæ·±åº¦ï¼ˆ10/10ï¼‰**
   - å‘ç°äº†Simpson's Paradoxï¼šæ•´ä½“ä¸Šfeature Xä¸ç³–å°¿ç—…æ­£ç›¸å…³ï¼Œä½†åˆ†ç§æ—çœ‹æ˜¯è´Ÿç›¸å…³
   - è¯†åˆ«äº†sampling biasï¼šæŸäº›ç§æ—ç¾¤ä½“ä¸¥é‡underrepresented
   - ç”¨QQ Plotå±•ç¤ºäº†è¡€ç³–å€¼çš„éæ­£æ€åˆ†å¸ƒ
   - æ£€æµ‹åˆ°å¹´é¾„-BMIçš„multicollinearityï¼ˆVIF>10ï¼‰

3. **æ•°æ®å‡†å¤‡ï¼ˆ10/10ï¼‰**
   - ç¼ºå¤±å€¼ï¼šç”¨MICEè€Œéç®€å•å¡«è¡¥ï¼Œå¹¶è§£é‡Šä¸ºä»€ä¹ˆ
   - ç¦»ç¾¤å€¼ï¼šä¿ç•™æé«˜è¡€ç³–å€¼ï¼ˆçœŸå®ç—…ä¾‹ï¼‰ï¼Œåˆ é™¤å¹´é¾„>120ï¼ˆé”™è¯¯æ•°æ®ï¼‰
   - åˆ›å»ºäº†BMI categories, age groupsç­‰é¢†åŸŸçŸ¥è¯†ç‰¹å¾
   - å¯¹åæ€ç‰¹å¾åšäº†Box-Coxè½¬æ¢ï¼Œå±•ç¤ºäº†QQ plotæ”¹å–„

4. **Biasç¼“è§£ï¼ˆ10/10ï¼‰**
   - é‡åŒ–äº†ä¸åŒç§æ—çš„è¯¯è¯Šç‡å·®å¼‚ï¼ˆé«˜è¾¾15%ï¼‰
   - ä½¿ç”¨é‡é‡‡æ ·ä½¿å„ç§æ—æ ·æœ¬å¹³è¡¡
   - å¯¹æ¯”äº†å…¬å¹³æ€§æŒ‡æ ‡ï¼šDemographic Parity, Equal Opportunity
   - è®¨è®ºäº†accuracy-fairness trade-off

5. **æ¨¡å‹å¯¹æ¯”ï¼ˆ10/10ï¼‰**
   - Minimalç‰ˆæœ¬ï¼šåªåˆ é™¤ç©ºè¡Œ â†’ Accuracy 0.80, AUC 0.82
   - Fullç‰ˆæœ¬ï¼šå®Œæ•´å‡†å¤‡ â†’ Accuracy 0.86, AUC 0.91
   - åšäº†æ¶ˆèå®éªŒï¼šé€æ­¥æ·»åŠ æ•°æ®å‡†å¤‡æ­¥éª¤ï¼Œçœ‹å¢ç›Š
   - åˆ†æäº†å“ªä¸ªæ­¥éª¤è´¡çŒ®æœ€å¤§ï¼ˆç‰¹å¾å·¥ç¨‹ +0.08 AUCï¼‰

6. **æ´å¯Ÿæ·±åº¦ï¼ˆ10/10ï¼‰**
   - å‘ç°é«˜BMIæ‚£è€…è¢«over-diagnosedï¼Œä½æ”¶å…¥æ‚£è€…è¢«under-diagnosed
   - è§£é‡Šäº†ä¸ºä»€ä¹ˆï¼šæ•°æ®æ”¶é›†biasï¼ˆåŒ»é™¢ä¸»è¦åœ¨å¯Œè£•ç¤¾åŒºï¼‰
   - æå‡ºæ”¹è¿›ï¼šéœ€è¦æ”¶é›†æ›´å¤šä½æ”¶å…¥ç¤¾åŒºæ•°æ®
   - ä¼¦ç†è®¨è®ºï¼šæ¨¡å‹å¯èƒ½åŠ å‰§åŒ»ç–—ä¸å¹³ç­‰

7. **æ¼”ç¤ºè´¨é‡ï¼ˆ10/10ï¼‰**
   - å¼€åœºç”¨ç—…äººæ•…äº‹å¼•å…¥
   - PPTæç®€ï¼Œæ¯é¡µä¸€ä¸ªé‡ç‚¹
   - å±•ç¤ºäº†ä¸€ä¸ªéœ‡æ’¼çš„å¯è§†åŒ–ï¼šåŒæ ·ç—‡çŠ¶çš„é»‘äººå’Œç™½äººé¢„æµ‹æ¦‚ç‡å·®å¼‚
   - 11åˆ†58ç§’ï¼Œå®Œç¾åˆ©ç”¨æ—¶é—´
   - æ‰€æœ‰æˆå‘˜è¡¨è¾¾æ¸…æ™°ï¼Œè¿‡æ¸¡è‡ªç„¶

8. **Notebookè´¨é‡ï¼ˆ10/10ï¼‰**
   - ç»“æ„æ¸…æ™°ï¼Œåƒä¸€æœ¬æ•™ç§‘ä¹¦
   - æ¯ä¸ªå†³ç­–éƒ½æœ‰è¯¦ç»†è§£é‡Šå’Œè¯æ®
   - ä»£ç ä¼˜é›…ï¼Œæ³¨é‡Šå……åˆ†
   - Markdownå†™å¾—åƒè®ºæ–‡
   - æ‰€æœ‰å›¾è¡¨éƒ½èƒ½å¤ç°

9. **åŸåˆ›æ€§ï¼ˆ10/10ï¼‰**
   - è‡ªå·±è®¾è®¡äº†ä¸€ä¸ª"Fairness Score"
   - åˆ›æ–°åœ°å¯è§†åŒ–äº†bias propagation
   - å¼•ç”¨äº†ç›¸å…³åŒ»ç–—å…¬å¹³æ€§æ–‡çŒ®
   - æå‡ºäº†æ•°æ®æ”¶é›†æ”¹è¿›æ–¹æ¡ˆ

**æ€»åˆ†ï¼š95/100**ï¼ˆæ‰£5åˆ†å› ä¸º...æ€»å¾—æ‰¾ç‚¹å°ç‘•ç–µå§ğŸ˜„ï¼‰

---

## ğŸ“š æ¨èèµ„æº

### æ•°æ®é›†ç½‘ç«™ï¼ˆæŒ‰æ¨èåº¦æ’åºï¼‰
```
1. â­â­â­â­â­ Kaggle
   - æ•°æ®è´¨é‡é«˜ï¼Œæ–‡æ¡£å®Œæ•´
   - æœ‰ç°æˆçš„kernelå¯ä»¥å‚è€ƒ
   - æ¨èdatasetsï¼š
     * Credit Card Fraud
     * Adult Income
     * Heart Disease

2. â­â­â­â­ UCI ML Repository
   - ç»å…¸æ•°æ®é›†ï¼Œæœ‰è®ºæ–‡æ”¯æŒ
   - æ¨èï¼šAdult, German Credit, COMPAS

3. â­â­â­â­ Data.gov.sg
   - æœ¬åœ°æ•°æ®ï¼Œæœ‰ç°å®æ„ä¹‰
   - æ¨èï¼šHDB Resale, Healthcare

4. â­â­â­ Our World in Data
   - ç¤¾ä¼šé—®é¢˜æ•°æ®ï¼Œæœ‰æ•…äº‹æ€§
   - æ¨èï¼šCOVID, Inequality, Education
```

### å­¦ä¹ èµ„æº
```
EDA & Visualization:
- Seaborn Gallery: https://seaborn.pydata.org/examples/index.html
- Matplotlib Tutorials: https://matplotlib.org/stable/tutorials/index.html

Statistics:
- Simpson's Paradox: https://en.wikipedia.org/wiki/Simpson%27s_paradox
- Statistical Tests: https://www.statsmodels.org/

Fairness in ML:
- Fairlearn: https://fairlearn.org/
- AI Fairness 360: https://aif360.mybluemix.net/

Presentation Skills:
- TED Talk tips: https://www.ted.com/playlists/574/how_to_make_a_great_presentation
```

---

## ğŸ‰ æœ€åçš„é¼“åŠ±

```
è®°ä½ï¼š

1. è¿™ä¸æ˜¯ä¸€ä¸ªæ¯”æ‹¼æ¨¡å‹å‡†ç¡®ç‡çš„ä½œä¸š
   â†’ ä½ çš„æ´å¯Ÿå’Œè§£é‡Šæ¯”æ•°å­—æ›´é‡è¦

2. æ•™æˆæƒ³çœ‹åˆ°çš„æ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹
   â†’ å±•ç¤ºä½ å¦‚ä½•åšå†³ç­–ï¼Œè€Œéå®Œç¾ç»“æœ

3. Biaså’Œå…¬å¹³æ€§æ˜¯åŠ åˆ†é‡ç‚¹
   â†’ è¿™æ˜¯AI Ethicsçš„æ ¸å¿ƒï¼Œå¤šèŠ±æ—¶é—´åœ¨è¿™ä¸Šé¢

4. å›¢é˜Ÿåä½œå¾ˆé‡è¦
   â†’ åˆ†å·¥æ˜ç¡®ï¼Œäº’ç›¸reviewï¼Œå…±åŒè¿›æ­¥

5. æå‰å¼€å§‹ï¼Œé¿å…deadlineå‹åŠ›
   â†’ Week 1å°±è¦é€‰å¥½æ•°æ®é›†ï¼

6. äº«å—è¿™ä¸ªè¿‡ç¨‹
   â†’ ä½ åœ¨å­¦ä¹ AIä»ä¸šè€…æœ€é‡è¦çš„æŠ€èƒ½ä¹‹ä¸€

Good luck! ä½ ä»¬ä¸€å®šèƒ½æ‹¿é«˜åˆ†ï¼ğŸ’ª
```

---

## é™„å½•ï¼šå¿«é€Ÿå‚è€ƒ

### è¯„åˆ†åˆ†å¸ƒæé†’
- Appropriateness (25%): æ–¹æ³•é€‰æ‹©æ˜¯å¦åˆé€‚
- Correctness (25%): æŠ€æœ¯æ­£ç¡®æ€§+è¡¨è¾¾æ¸…æ™°åº¦
- Interpretation (25%): åˆ†æåˆ¤æ–­åŠ›ï¼ˆè¯†åˆ«è°¬è¯¯ï¼‰
- Novelty (25%): åŸåˆ›æ€§å’Œæ·±åº¦æ´å¯Ÿ

### ç¦æ­¢ä½¿ç”¨çš„æ¨¡å‹
âŒ Random Forest
âŒ XGBoost / LightGBM
âŒ Neural Networks
âŒ SVM (å¤æ‚æ ¸å‡½æ•°)
âŒ Ensemble methods

### å…è®¸ä½¿ç”¨çš„æ¨¡å‹
âœ… Logistic Regression
âœ… Linear Regression
âœ… Decision Tree (æ·±åº¦â‰¤5)

### Deadline
- Video + Notebook: Week 5 (Feb 8, 12:00)
- Peer Evaluation: Week 6 (Feb 14, 12:00)

### æäº¤æ¸…å•
â–¡ YouTubeå…¬å¼€é“¾æ¥ï¼ˆæ ‡é¢˜å«ç»„å·ï¼‰
â–¡ .ipynbæ–‡ä»¶ï¼ˆæ–‡ä»¶åå«ç»„å·ï¼‰
â–¡ è§†é¢‘â‰¤12åˆ†é’Ÿ
â–¡ æ‰€æœ‰æˆå‘˜å‡ºé•œ
â–¡ ä»£ç å¯è¿è¡Œ
