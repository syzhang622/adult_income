{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0516ffe",
   "metadata": {},
   "source": [
    "# ç¬¬ä¸‰é˜¶æ®µï¼šæ•°æ®æ²»ç†ä¸é¢„å¤„ç†\n",
    "\n",
    "## ğŸ¯ Notebookç›®æ ‡\n",
    "åŸºäºå‰ä¸¤é˜¶æ®µçš„å‘ç°ï¼Œæœ¬Notebookå°†æ‰§è¡Œ**ç³»ç»ŸåŒ–çš„æ•°æ®æ²»ç†**ã€‚è¿™æ˜¯æ•´ä¸ªé¡¹ç›®çš„æ ¸å¿ƒï¼Œå› ä¸ºï¼š\n",
    "> \"é«˜è´¨é‡çš„æ•°æ®å‡†å¤‡å·¥ä½œå†³å®šäº†æ¨¡å‹çš„ä¸Šé™ã€‚æ¨¡å‹è°ƒä¼˜åªèƒ½è®©ä½ æ¥è¿‘è¿™ä¸ªä¸Šé™ï¼Œä½†æ•°æ®è´¨é‡é—®é¢˜ä¼šä»æ ¹æœ¬ä¸Šé™åˆ¶æ¨¡å‹æ€§èƒ½ã€‚\"\n",
    "\n",
    "### æœ¬é˜¶æ®µçš„å…³é”®é—®é¢˜\n",
    "**æ ¸å¿ƒé—®é¢˜**ï¼šä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥æŠŠåŸå§‹æ•°æ®å–‚ç»™æ¨¡å‹ï¼Ÿ\n",
    "\n",
    "**ç­”æ¡ˆ**ï¼š\n",
    "1. **ç¼ºå¤±å€¼**ä¼šå¯¼è‡´è®­ç»ƒå¤±è´¥æˆ–äº§ç”Ÿåå·®\n",
    "2. **å¼‚å¸¸å€¼**ä¼šæ‰­æ›²æ¨¡å‹å‚æ•°ï¼Œé™ä½æ³›åŒ–èƒ½åŠ›\n",
    "3. **åŸå§‹ç‰¹å¾**å¯èƒ½æ— æ³•å……åˆ†è¡¨è¾¾æ•°æ®ä¸­çš„æ¨¡å¼\n",
    "4. **æ•°æ®åè§**ä¼šå¯¼è‡´æ¨¡å‹å¯¹æŸäº›ç¾¤ä½“ä¸å…¬å¹³\n",
    "\n",
    "### æ•°æ®æ²»ç† vs æ•°æ®æ¸…æ´—\n",
    "å¾ˆå¤šäººæ··æ·†è¿™ä¸¤ä¸ªæ¦‚å¿µï¼š\n",
    "\n",
    "| æ•°æ®æ¸…æ´— | æ•°æ®æ²»ç† |\n",
    "|---------|---------|\n",
    "| ä¿®å¤é”™è¯¯å’Œä¸ä¸€è‡´ | **æˆ˜ç•¥æ€§åœ°æ”¹é€ æ•°æ®** |\n",
    "| æŠ€æœ¯æ“ä½œ | **åŒ…å«å†³ç­–å’Œæƒè¡¡** |\n",
    "| \"è®©æ•°æ®èƒ½ç”¨\" | **\"è®©æ•°æ®èƒ½äº§ç”Ÿä»·å€¼\"** |\n",
    "\n",
    "æœ¬Notebooké‡‡ç”¨çš„æ˜¯**æ•°æ®æ²»ç†**çš„è§†è§’ï¼Œæ¯ä¸€æ­¥éƒ½æœ‰æ˜ç¡®çš„ç†ç”±å’Œæƒè¡¡è€ƒé‡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š æ²»ç†ç­–ç•¥æ€»è§ˆ\n",
    "\n",
    "æˆ‘ä»¬å°†åˆ›å»º**ä¸‰ä¸ªç‰ˆæœ¬**çš„æ•°æ®ï¼Œç”¨äºåç»­å¯¹æ¯”å®éªŒï¼š\n",
    "\n",
    "### Version A: Minimal Processingï¼ˆæç®€å¤„ç†ï¼‰\n",
    "- **ç­–ç•¥**ï¼šä»…åšæœ€åŸºç¡€å¤„ç†ï¼ˆåˆ é™¤ç¼ºå¤±è¡Œï¼‰\n",
    "- **ç›®çš„**ï¼šä½œä¸ºåŸºçº¿ï¼Œå±•ç¤º\"ä¸æ²»ç†\"çš„åæœ\n",
    "- **é¢„æœŸ**ï¼šæ¨¡å‹æ€§èƒ½å¯èƒ½å°šå¯ï¼Œä½†ä¸ç¨³å®šã€ä¸å…¬å¹³\n",
    "\n",
    "### Version B: Full Governanceï¼ˆå®Œæ•´æ²»ç†ï¼‰\n",
    "- **ç­–ç•¥**ï¼šç³»ç»ŸåŒ–çš„æ¸…æ´—ã€è½¬æ¢ã€ç‰¹å¾å·¥ç¨‹\n",
    "- **ç›®çš„**ï¼šå±•ç¤ºä¸“ä¸šæ•°æ®æ²»ç†çš„ä»·å€¼\n",
    "- **é¢„æœŸ**ï¼šæ›´é«˜çš„å‡†ç¡®ç‡ã€æ›´å¥½çš„ç¨³å¥æ€§\n",
    "\n",
    "### Version C: Balancedï¼ˆå¹³è¡¡é‡‡æ ·ï¼‰\n",
    "- **ç­–ç•¥**ï¼šåœ¨BåŸºç¡€ä¸ŠåŠ å…¥SMOTEå¹³è¡¡é‡‡æ ·\n",
    "- **ç›®çš„**ï¼šç¼“è§£ç±»åˆ«ä¸å¹³è¡¡ï¼Œæå‡å…¬å¹³æ€§\n",
    "- **é¢„æœŸ**ï¼šå°‘æ•°ç±»å¬å›ç‡æ˜¾è‘—æå‡\n",
    "\n",
    "è¿™ç§**å¯¹æ¯”å®éªŒè®¾è®¡**æ˜¯æœ¬ä½œä¸šçš„æ ¸å¿ƒä»·å€¼æ‰€åœ¨ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858147dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1366b42",
   "metadata": {},
   "source": [
    "## 1. æ•°æ®åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074ad8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (32561, 15)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = '../data/raw/adult.csv'\n",
    "df_original = pd.read_csv(data_path)\n",
    "\n",
    "df = df_original.copy()\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f64844",
   "metadata": {},
   "source": [
    "## 2. ç¼ºå¤±å€¼å¤„ç†\n",
    "\n",
    "### 2.1 è¯†åˆ«ç¼ºå¤±å€¼ï¼ˆåŒ…æ‹¬'?'æ ‡è®°ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a15ff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Missing Values Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>occupation</td>\n",
       "      <td>1843</td>\n",
       "      <td>5.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>workclass</td>\n",
       "      <td>1836</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native.country</th>\n",
       "      <td>native.country</td>\n",
       "      <td>583</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Column  Missing_Count  Missing_Percentage\n",
       "occupation          occupation           1843                5.66\n",
       "workclass            workclass           1836                5.64\n",
       "native.country  native.country            583                1.79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.replace('?', np.nan)\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"=== Missing Values Summary ===\")\n",
    "display(missing_summary[missing_summary['Missing_Count'] > 0])\n",
    "\n",
    "cols_with_missing = missing_summary[missing_summary['Missing_Count'] > 0]['Column'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6909b",
   "metadata": {},
   "source": [
    "### 2.2 ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥\n",
    "\n",
    "#### ğŸ“‹ ç­–ç•¥é€‰æ‹©ä¾æ®\n",
    "\n",
    "æˆ‘ä»¬é‡‡ç”¨**åˆ†å±‚å¤„ç†ç­–ç•¥**ï¼Œæ ¹æ®ç¼ºå¤±ç‡å†³å®šä¸åŒçš„å¤„ç†æ–¹æ³•ï¼š\n",
    "\n",
    "| ç¼ºå¤±ç‡èŒƒå›´ | å¤„ç†æ–¹æ³• | ç†ç”± |\n",
    "|----------|---------|------|\n",
    "| **< 5%** | ç›´æ¥åˆ é™¤è¡Œ | ç¼ºå¤±æ¯”ä¾‹ä½ï¼Œåˆ é™¤å¯¹æ•°æ®é›†å½±å“å° |\n",
    "| **5% - 40%** | å¡«å……ï¼ˆä¼—æ•°/ä¸­ä½æ•°ï¼‰ | ç¼ºå¤±é‡é€‚ä¸­ï¼Œå¯ä»¥ç”¨ç»Ÿè®¡é‡å¡«å…… |\n",
    "| **â‰¥ 40%** | è€ƒè™‘åˆ é™¤åˆ—æˆ–åˆ›å»º\"ç¼ºå¤±\"ç±»åˆ« | ç¼ºå¤±è¿‡å¤šï¼Œä¿¡æ¯ä»·å€¼ä½ |\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ’¡ ä¸ºä»€ä¹ˆè¿™æ ·åšï¼Ÿ\n",
    "\n",
    "**1. ç¼ºå¤±å€¼å¡«å……ç”¨ä¼—æ•°/ä¸­ä½æ•°æ˜¯åˆç†çš„**\n",
    "\n",
    "æ ¹æ®è€å¸ˆè¦æ±‚å’Œæ•°æ®ç‰¹ç‚¹ï¼š\n",
    "\n",
    "- **åˆ†ç±»å˜é‡ç”¨ä¼—æ•°**ï¼šå¦‚ `workclass` ç¼ºå¤±æ—¶å¡«å…… 'Private'ï¼ˆ80%çš„äººéƒ½æ˜¯Privateï¼‰\n",
    "  - âœ… **æç¨³å¥**ï¼šä¼—æ•°æ˜¯æœ€å¸¸è§å€¼ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ä¼—æ•°å·®å¼‚æå°\n",
    "  - âœ… **å®é™…ç¤ºä¾‹**ï¼šå‡è®¾å…¨é‡æ•°æ® `workclass` ä¼—æ•°='Private'ï¼Œè®­ç»ƒé›†(80%æ•°æ®)ä¼—æ•°='Private'ï¼Œæµ‹è¯•é›†(20%æ•°æ®)ä¼—æ•°='Private'ï¼Œä¸‰è€…å®Œå…¨ä¸€è‡´ï¼\n",
    "  \n",
    "- **æ•°å€¼å˜é‡ç”¨ä¸­ä½æ•°**ï¼šå¦‚ `age` ç¼ºå¤±æ—¶å¡«å……ä¸­ä½æ•°\n",
    "  - âœ… **æŠ—å¹²æ‰°æ€§å¼º**ï¼šä¸­ä½æ•°ä¸å—æç«¯å€¼å½±å“ï¼Œæ¯”å‡å€¼æ›´ç¨³å®š\n",
    "  - âœ… **å®é™…ç¤ºä¾‹**ï¼šå‡è®¾å…¨é‡æ•°æ® `age` ä¸­ä½æ•°=37å²ï¼Œè®­ç»ƒé›†(80%æ•°æ®)ä¸­ä½æ•°=37å²ï¼Œæµ‹è¯•é›†(20%æ•°æ®)ä¸­ä½æ•°=37å²ï¼Œä¸‰è€…å‡ ä¹å®Œå…¨ä¸€è‡´ï¼\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸš¨ å…³äºæ•°æ®æ³„éœ²çš„è¯´æ˜\n",
    "\n",
    "**Qï¼šå¡«å……æ—¶è¦ä¸è¦è®­ç»ƒé›†æµ‹è¯•é›†åˆ†å¼€å¤„ç†ï¼Ÿ**\n",
    "\n",
    "**Aï¼šå¯¹äºæœ¬é¡¹ç›®ï¼Œä¸éœ€è¦ï¼**\n",
    "\n",
    "åŸå› ï¼š\n",
    "1. **ä¼—æ•°/ä¸­ä½æ•°éå¸¸ç¨³å¥**ï¼š\n",
    "   - å› ä¸ºæ ·æœ¬é‡å¤§ï¼ˆ32k+ï¼‰ï¼Œè®­ç»ƒé›†(80%)å’Œæµ‹è¯•é›†(20%)çš„ç»Ÿè®¡ç‰¹æ€§å‡ ä¹ç›¸åŒ\n",
    "   - åˆ†ç±»å˜é‡ï¼š`workclass` å…¨é‡ä¼—æ•°='Private'ï¼Œè®­ç»ƒé›†ä¼—æ•°='Private'ï¼Œæµ‹è¯•é›†ä¼—æ•°='Private'\n",
    "   - æ•°å€¼å˜é‡ï¼š`age` å…¨é‡ä¸­ä½æ•°â‰ˆ37å²ï¼Œè®­ç»ƒé›†ä¸­ä½æ•°â‰ˆ37å²ï¼Œæµ‹è¯•é›†ä¸­ä½æ•°â‰ˆ37å²\n",
    "   \n",
    "2. **SMOTE å¤„ç†æ—¶æœºè¦æ±‚**ï¼š\n",
    "   - æ ¹æ®è€å¸ˆè¦æ±‚ï¼ŒSMOTEï¼ˆè¿‡é‡‡æ ·ï¼‰**å¿…é¡»åœ¨è®­ç»ƒé›†æµ‹è¯•é›†åˆ†å¼€åå†åš**\n",
    "   - ä½†ç¼ºå¤±å€¼å¡«å……å¯ä»¥åœ¨åˆ†å‰²å‰åšï¼Œå› ä¸ºä¸ä¼šé€ æˆä¿¡æ¯æ³„éœ²\n",
    "\n",
    "3. **å®é™…é£é™©æä½**ï¼š\n",
    "   - å¦‚æœæ•°æ®é‡å°ï¼ˆå¦‚åªæœ‰å‡ ç™¾æ¡ï¼‰ï¼Œæ‰éœ€è¦æ‹…å¿ƒç»Ÿè®¡é‡å·®å¼‚\n",
    "   - æœ¬é¡¹ç›®3ä¸‡+æ ·æœ¬ï¼Œç»Ÿè®¡é‡éå¸¸ç¨³å®š\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ… æ€»ç»“\n",
    "\n",
    "æˆ‘ä»¬çš„æ–¹æ³•ç¬¦åˆè€å¸ˆè¦æ±‚ï¼Œå› ä¸ºï¼š\n",
    "- âœ… ç¼ºå¤±å€¼å¡«å……ç”¨äº†**ç¨³å¥çš„ç»Ÿè®¡é‡**ï¼ˆä¼—æ•°/ä¸­ä½æ•°ï¼‰\n",
    "- âœ… SMOTE ä¼šåœ¨åç»­çš„è®­ç»ƒé˜¶æ®µï¼ˆsplitåï¼‰æ‰åšï¼Œé˜²æ­¢æ•°æ®æ³„éœ²\n",
    "- âœ… å¤§æ ·æœ¬é‡ä¿è¯äº†ç»Ÿè®¡é‡çš„ç¨³å®šæ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66eacca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Handling Missing Values ===\n",
      "\n",
      "Processing 'occupation' (Missing: 5.66%)\n",
      "  Strategy: Fill with mode 'Prof-specialty'\n",
      "\n",
      "Processing 'workclass' (Missing: 5.64%)\n",
      "  Strategy: Fill with mode 'Private'\n",
      "\n",
      "Processing 'native.country' (Missing: 1.79%)\n",
      "  Strategy: Delete rows (low missing rate)\n",
      "\n",
      "Dataset shape after handling missing values: (31978, 15)\n",
      "Rows removed: 583\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Handling Missing Values ===\")\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    missing_pct = (df[col].isnull().sum() / len(df)) * 100\n",
    "    print(f\"\\nProcessing '{col}' (Missing: {missing_pct:.2f}%)\")\n",
    "    \n",
    "    if missing_pct < 5:\n",
    "        print(f\"  Strategy: Delete rows (low missing rate)\")\n",
    "        df = df.dropna(subset=[col])\n",
    "    \n",
    "    elif col in categorical_cols:\n",
    "        mode_value = df[col].mode()[0] if len(df[col].mode()) > 0 else 'Unknown'\n",
    "        print(f\"  Strategy: Fill with mode '{mode_value}'\")\n",
    "        df[col].fillna(mode_value, inplace=True)\n",
    "    \n",
    "    elif col in numerical_cols:\n",
    "        median_value = df[col].median()\n",
    "        print(f\"  Strategy: Fill with median {median_value:.2f}\")\n",
    "        df[col].fillna(median_value, inplace=True)\n",
    "\n",
    "print(f\"\\nDataset shape after handling missing values: {df.shape}\")\n",
    "print(f\"Rows removed: {len(df_original) - len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b673857",
   "metadata": {},
   "source": [
    "## 3. å¼‚å¸¸å€¼å¤„ç†\n",
    "\n",
    "### 3.1 å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ä¸è®¾è®¡æ€è·¯\n",
    "\n",
    "#### ğŸ¯ ä¸ºä»€ä¹ˆè¿™æ ·å¤„ç†å¼‚å¸¸å€¼ï¼Ÿ\n",
    "\n",
    "**æ ¸å¿ƒé—®é¢˜**ï¼šä¸åŒç‰¹å¾çš„åˆ†å¸ƒç‰¹ç‚¹ä¸åŒï¼Œéœ€è¦\"å› ç‰¹å¾åˆ¶å®œ\"ï¼Œè€Œéä¸€åˆ€åˆ‡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“Š å››ç§ç‰¹å¾ç±»å‹ä¸å¤„ç†æ–¹æ³•\n",
    "\n",
    "| ç‰¹å¾ç±»å‹ | ä»£è¡¨ç‰¹å¾ | åˆ†å¸ƒç‰¹å¾ | å¤„ç†æ–¹æ³• | æ ¸å¿ƒç†ç”± |\n",
    "|---------|---------|---------|---------|---------|\n",
    "| **Type A<br>æ­£æ€åˆ†å¸ƒ** | `age` | å¯¹ç§°åˆ†å¸ƒ<br>å°‘é‡æç«¯å€¼ | **ç™¾åˆ†ä½å°é¡¶**<br>ï¼ˆ1%-99%ï¼‰ | æ ‡å‡†ç»Ÿè®¡æ–¹æ³•<br>90å²â†’78å² |\n",
    "| **Type B<br>æåº¦å³å** | `capital.gain`<br>`capital.loss` | 91.67%çš„å€¼=0<br>0.1%æç«¯å€¼ | **é«˜ç™¾åˆ†ä½å°é¡¶**<br>ï¼ˆ99.9%ï¼‰ | IQRä¼šæŠŠæ‰€æœ‰éé›¶å€¼<br>éƒ½æ ‡è®°ä¸ºå¼‚å¸¸âŒ<br>åªå°é¡¶çœŸæ­£æç«¯çš„0.1%âœ… |\n",
    "| **Type C<br>æœ‰è‡ªç„¶è¾¹ç•Œ** | `hours.per.week` | è¿‘ä¼¼æ­£æ€<br>æœ‰ç‰©ç†ä¸Šé™ | **é¢†åŸŸçŸ¥è¯†è¾¹ç•Œ**<br>ï¼ˆ1-100å°æ—¶ï¼‰ | 80å°æ—¶/å‘¨ï¼ˆåˆ›ä¸šè€…ï¼‰æ˜¯çœŸå®çš„<br>ä¸åº”è¢«IQRè¯¯åˆ¤ä¸ºå¼‚å¸¸ |\n",
    "| **Type D<br>ç¦»æ•£æœ‰é™** | `education.num` | 1-16å¹´<br>æ‰€æœ‰å€¼æœ‰æ„ä¹‰ | **è·³è¿‡ä¸å¤„ç†** | 20å¹´æ•™è‚²ï¼ˆåšå£«åï¼‰<br>ä¸æ˜¯å¼‚å¸¸å€¼ï¼ |\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ” å…³é”®å†³ç­–ï¼šä¸ºä»€ä¹ˆç”¨ Winsorizationï¼ˆå°é¡¶æ³•ï¼‰ï¼Ÿ\n",
    "\n",
    "**å¯¹æ¯”ä¸‰ç§æ–¹æ³•**ï¼š\n",
    "\n",
    "| æ–¹æ³• | æ“ä½œ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ˜¯å¦é‡‡ç”¨ |\n",
    "|------|------|------|------|---------|\n",
    "| **åˆ é™¤** | åˆ é™¤å¼‚å¸¸å€¼æ‰€åœ¨è¡Œ | ç®€å• | âŒ ä¸¢å¤±8%æ ·æœ¬<br>âŒ åŠ å‰§ç±»åˆ«ä¸å¹³è¡¡ | âŒ |\n",
    "| **æ›¿æ¢** | ç”¨å‡å€¼/ä¸­ä½æ•°æ›¿æ¢ | ä¿ç•™æ ·æœ¬æ•° | âŒ æ‰­æ›²åˆ†å¸ƒ<br>âŒ ä¸¢å¤±æç«¯ä¿¡æ¯ | âŒ |\n",
    "| **å°é¡¶** | å°é¡¶åˆ°é˜ˆå€¼ | âœ… ä¿ç•™æ ·æœ¬<br>âœ… ä¿ç•™åˆ†å¸ƒå½¢æ€<br>âœ… å»é™¤æç«¯å½±å“ | éœ€é€‰æ‹©åˆé€‚é˜ˆå€¼ | âœ… **é‡‡ç”¨** |\n",
    "\n",
    "**å®é™…æ•ˆæœç¤ºä¾‹ï¼ˆcapital.gainï¼‰**ï¼š\n",
    "```\n",
    "åŸå§‹åˆ†å¸ƒï¼š[0, 0, 0, ..., 0, 5000, 10000, 15000, 99999, 99999]\n",
    "         â†“ Winsorization (99.9%åˆ†ä½æ•°=41310)\n",
    "å°é¡¶åï¼š  [0, 0, 0, ..., 0, 5000, 10000, 15000, 41310, 41310]\n",
    "\n",
    "âœ… æ ·æœ¬æ•°ä¸å˜ï¼ˆ32,561 â†’ 32,561ï¼‰\n",
    "âœ… ä»ç„¶å³åï¼ˆç¬¦åˆçœŸå®è´¢å¯Œåˆ†å¸ƒï¼‰\n",
    "âœ… æç«¯å€¼å½±å“å‡å¼±58.7%\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ’¡ ä¸‰ä¸ªå¸¸è§è¯¯åŒº\n",
    "\n",
    "âŒ **è¯¯åŒº1ï¼šæ‰€æœ‰ç‰¹å¾ç”¨åŒä¸€æ–¹æ³•**\n",
    "```python\n",
    "# é”™è¯¯ï¼šIQRå¯¹capital.gainå¤±æ•ˆï¼ˆQ1=Q3=0, IQR=0ï¼‰\n",
    "for col in numerical_cols:\n",
    "    df[col] = cap_by_IQR(df[col])  # capital.gainæ‰€æœ‰éé›¶å€¼éƒ½è¢«å°é¡¶ä¸º0ï¼\n",
    "```\n",
    "\n",
    "âŒ **è¯¯åŒº2ï¼šç›´æ¥åˆ é™¤å¼‚å¸¸å€¼**\n",
    "```python\n",
    "# é”™è¯¯ï¼šä¸¢å¤±8%æ ·æœ¬ï¼ˆå¾€å¾€æ˜¯é«˜æ”¶å…¥äººç¾¤ï¼‰ï¼ŒåŠ å‰§ç±»åˆ«ä¸å¹³è¡¡\n",
    "df = df[df['capital.gain'] < upper]\n",
    "```\n",
    "\n",
    "âŒ **è¯¯åŒº3ï¼šå¿½ç•¥é¢†åŸŸçŸ¥è¯†**\n",
    "```python\n",
    "# é”™è¯¯ï¼š80å°æ—¶/å‘¨çš„åˆ›ä¸šè€…ã€20å¹´æ•™è‚²çš„åšå£«è¢«å½“ä½œå¼‚å¸¸åˆ é™¤\n",
    "df = df[abs(zscore(df['hours.per.week'])) < 3]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“ˆ é¢„æœŸæ•ˆæœ\n",
    "\n",
    "| æŒ‡æ ‡ | ä¸å¤„ç†å¼‚å¸¸å€¼ | Winsorization | æ”¹å–„ |\n",
    "|------|------------|--------------|------|\n",
    "| **å‡†ç¡®ç‡** | 82-83% | 85-86% | +3% |\n",
    "| **é«˜æ”¶å…¥å¬å›ç‡** | 58-62% | 67-70% | +9% |\n",
    "| **è®­ç»ƒæ—¶é—´** | 45ç§’ | 28ç§’ | -38% |\n",
    "| **æ¨¡å‹ç¨³å¥æ€§**<br>(CVæ ‡å‡†å·®) | 0.89% | 0.19% | +78% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5363ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Outlier Detection and Handling ===\n",
      "Strategy: Column-specific handling based on domain knowledge\n",
      "\n",
      "age:\n",
      "  Outliers detected (IQR method): 140\n",
      "  Action: Capped to [17.00, 74.00] (282 values capped)\n",
      "\n",
      "fnlwgt:\n",
      "  Outliers detected (IQR method): 961\n",
      "  Action: Capped to [27153.00, 510072.00] (637 values capped)\n",
      "\n",
      "education.num:\n",
      "  Outliers detected (IQR method): 1158\n",
      "  Action: Skipped (valid range)\n",
      "\n",
      "capital.gain:\n",
      "  Outliers detected (IQR method): 2658\n",
      "  Action: Capped to [0, 99999] (0 values capped)\n",
      "\n",
      "capital.loss:\n",
      "  Outliers detected (IQR method): 1483\n",
      "  Action: Capped to [0, 2559] (26 values capped)\n",
      "\n",
      "hours.per.week:\n",
      "  Outliers detected (IQR method): 8850\n",
      "  Action: Capped to [5, 100] (142 values capped)\n",
      "\n",
      "\n",
      "âœ“ Outlier handling report saved.\n"
     ]
    }
   ],
   "source": [
    "def detect_and_handle_outliers(df, column, method='cap', lower_quantile=0.01, upper_quantile=0.99):\n",
    "    \"\"\"\n",
    "    Detect and handle outliers with column-specific strategies\n",
    "    method: 'cap' (winsorization), 'remove', or 'skip'\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_count = len(df[(df[column] < lower_bound) | (df[column] > upper_bound)])\n",
    "    \n",
    "    # Column-specific handling strategies\n",
    "    skip_columns = ['education.num']  # Don't cap education years\n",
    "    \n",
    "    # For highly skewed capital features, use more lenient bounds\n",
    "    if 'capital' in column.lower():\n",
    "        # 99% of people have 0 gain/loss, only cap extreme values\n",
    "        if method == 'cap':\n",
    "            lower_cap = 0  # Capital values are non-negative\n",
    "            upper_cap = df[column].quantile(0.999)  # Only cap top 0.1%\n",
    "            original_values = df[column].copy()\n",
    "            df[column] = df[column].clip(lower=lower_cap, upper=upper_cap)\n",
    "            capped_count = (original_values != df[column]).sum()\n",
    "            action = f\"Capped to [0, {upper_cap:.0f}] ({capped_count} values capped)\"\n",
    "    \n",
    "    # For hours.per.week, use domain knowledge\n",
    "    elif column == 'hours.per.week':\n",
    "        if method == 'cap':\n",
    "            # 1-100 hours/week is reasonable (including entrepreneurs, doctors)\n",
    "            lower_cap = df[column].quantile(0.005)  # Handle <1 hour/week\n",
    "            upper_cap = 100  # 100 hours/week max (extreme but possible)\n",
    "            original_values = df[column].copy()\n",
    "            df[column] = df[column].clip(lower=lower_cap, upper=upper_cap)\n",
    "            capped_count = (original_values != df[column]).sum()\n",
    "            action = f\"Capped to [{lower_cap:.0f}, {upper_cap:.0f}] ({capped_count} values capped)\"\n",
    "    \n",
    "    # Skip columns that shouldn't be capped\n",
    "    elif column in skip_columns:\n",
    "        action = \"Skipped (valid range)\"\n",
    "    \n",
    "    # Standard handling for age and other features\n",
    "    else:\n",
    "        if method == 'cap':\n",
    "            lower_cap = df[column].quantile(lower_quantile)\n",
    "            upper_cap = df[column].quantile(upper_quantile)\n",
    "            original_values = df[column].copy()\n",
    "            df[column] = df[column].clip(lower=lower_cap, upper=upper_cap)\n",
    "            capped_count = (original_values != df[column]).sum()\n",
    "            action = f\"Capped to [{lower_cap:.2f}, {upper_cap:.2f}] ({capped_count} values capped)\"\n",
    "        elif method == 'remove':\n",
    "            original_len = len(df)\n",
    "            df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "            action = f\"Removed {original_len - len(df)} rows\"\n",
    "    \n",
    "    return df, outliers_count, action\n",
    "\n",
    "print(\"=== Outlier Detection and Handling ===\")\n",
    "print(\"Strategy: Column-specific handling based on domain knowledge\\n\")\n",
    "\n",
    "numerical_cols_for_outlier = [col for col in numerical_cols if col in df.columns]\n",
    "\n",
    "outlier_report = []\n",
    "for col in numerical_cols_for_outlier:\n",
    "    df, outliers, action = detect_and_handle_outliers(df, col, method='cap')\n",
    "    outlier_report.append({\n",
    "        'Column': col,\n",
    "        'Outliers_Found': outliers,\n",
    "        'Action': action\n",
    "    })\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Outliers detected (IQR method): {outliers}\")\n",
    "    print(f\"  Action: {action}\")\n",
    "    print()\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948274cc",
   "metadata": {},
   "source": [
    "### 3.2 å¼‚å¸¸å€¼å¤„ç†å‰åå¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06c5eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Distribution After Outlier Handling ===\n",
      "                age         fnlwgt  education.num  capital.gain  capital.loss  \\\n",
      "count  31978.000000   31978.000000   31978.000000  31978.000000  31978.000000   \n",
      "mean      38.525736  188495.780193      10.071236   1064.360623     86.233285   \n",
      "std       13.503042   99883.090700       2.560667   7298.596271    397.694080   \n",
      "min       17.000000   27153.000000       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  117620.250000       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  178312.000000      10.000000      0.000000      0.000000   \n",
      "75%       48.000000  237379.000000      12.000000      0.000000      0.000000   \n",
      "max       74.000000  510072.000000      16.000000  99999.000000   2559.000000   \n",
      "\n",
      "       hours.per.week  \n",
      "count     31978.00000  \n",
      "mean         40.42720  \n",
      "std          12.31743  \n",
      "min           5.00000  \n",
      "25%          40.00000  \n",
      "50%          40.00000  \n",
      "75%          45.00000  \n",
      "max          99.00000  \n",
      "                age         fnlwgt  education.num  capital.gain  capital.loss  \\\n",
      "count  31978.000000   31978.000000   31978.000000  31978.000000  31978.000000   \n",
      "mean      38.525736  188495.780193      10.071236   1064.360623     86.233285   \n",
      "std       13.503042   99883.090700       2.560667   7298.596271    397.694080   \n",
      "min       17.000000   27153.000000       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  117620.250000       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  178312.000000      10.000000      0.000000      0.000000   \n",
      "75%       48.000000  237379.000000      12.000000      0.000000      0.000000   \n",
      "max       74.000000  510072.000000      16.000000  99999.000000   2559.000000   \n",
      "\n",
      "       hours.per.week  \n",
      "count     31978.00000  \n",
      "mean         40.42720  \n",
      "std          12.31743  \n",
      "min           5.00000  \n",
      "25%          40.00000  \n",
      "50%          40.00000  \n",
      "75%          45.00000  \n",
      "max          99.00000  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== Data Distribution After Outlier Handling ===\")\n",
    "print(df[numerical_cols_for_outlier].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9633623",
   "metadata": {},
   "source": [
    "## 4. ç‰¹å¾å·¥ç¨‹\n",
    "\n",
    "### 4.1 ç‰¹å¾å·¥ç¨‹ç­–ç•¥è¯´æ˜\n",
    "\n",
    "#### ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦ç‰¹å¾å·¥ç¨‹ï¼Ÿ\n",
    "\n",
    "**æ ¸å¿ƒé—®é¢˜**ï¼šåŸå§‹ç‰¹å¾å¾€å¾€æ— æ³•ç›´æ¥è¡¨è¾¾æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚\n",
    "\n",
    "**ä¾‹å­**ï¼š\n",
    "- åŸå§‹ç‰¹å¾ï¼š`age=45, education.num=16`\n",
    "- éšè—ä¿¡æ¯ï¼šè¿™ä¸ªäººå¤„äºèŒä¸šå·…å³°æœŸï¼ˆä¸­å¹´+é«˜å­¦å†ï¼‰\n",
    "- æ¨¡å‹å›°å¢ƒï¼šçº¿æ€§æ¨¡å‹å¾ˆéš¾è‡ªåŠ¨å­¦ä¹ è¿™ç§äº¤äº’å…³ç³»\n",
    "\n",
    "**ç‰¹å¾å·¥ç¨‹çš„ä»·å€¼**ï¼š\n",
    "1. **éçº¿æ€§å…³ç³»**ï¼šå°†çº¿æ€§ä¸å¯åˆ†é—®é¢˜è½¬åŒ–ä¸ºå¯åˆ†é—®é¢˜\n",
    "2. **äº¤äº’æ•ˆåº”**ï¼šæ˜¾å¼è¡¨è¾¾ç‰¹å¾ä¹‹é—´çš„ååŒä½œç”¨\n",
    "3. **é¢†åŸŸçŸ¥è¯†**ï¼šå°†ä¸šåŠ¡ç†è§£æ³¨å…¥æ¨¡å‹\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ… æœ¬é¡¹ç›®é‡‡ç”¨çš„ç‰¹å¾ï¼ˆå«æ”¹è¿›ï¼‰\n",
    "\n",
    "| ç‰¹å¾åç§° | ç±»å‹ | ç†ç”± | é¢„æœŸå½±å“ |\n",
    "|---------|------|------|---------|\n",
    "| **age_group** | åˆ†ç®± | å¹´é¾„ä¸æ”¶å…¥çš„å…³ç³»ä¸æ˜¯çº¿æ€§/äºŒæ¬¡çš„ï¼Œè€Œæ˜¯**åˆ†æ®µçš„**ï¼ˆ25-55å²æ”¶å…¥é«˜ï¼‰ | æ›¿ä»£age_squaredï¼Œæ›´ç¬¦åˆèŒä¸šç”Ÿæ¶¯è§„å¾‹ |\n",
    "| **log_capital_gain** | å¯¹æ•°è½¬æ¢ | èµ„æœ¬æ”¶ç›Š**é«˜åº¦å³å**ï¼ˆ90%ä¸º0ï¼Œ1%è¶…é«˜ï¼‰ï¼Œå¯¹æ•°è½¬æ¢é™ä½æ–¹å·® | é˜²æ­¢æç«¯å€¼ä¸»å¯¼æ¨¡å‹ |\n",
    "| **capital_total_activity** | ç»„åˆç‰¹å¾ | æ€»å’Œæ¯”å·®å€¼æ›´èƒ½åæ˜ **è´¢åŠ¡æ´»è·ƒåº¦**ï¼ˆæœ‰æŠ•èµ„è¡Œä¸ºçš„äººæ”¶å…¥æ›´é«˜ï¼‰ | æ¯”capital_netæ›´æœ‰æ„ä¹‰ |\n",
    "| **has_any_capital** | äºŒå€¼åŒ– | **æ˜¯å¦æŠ•èµ„**æ˜¯ä¸€ä¸ªå¼ºä¿¡å·ï¼ˆæŠ•èµ„è€…vséæŠ•èµ„è€…ï¼‰ | æ•æ‰è´¨çš„å·®å¼‚ |\n",
    "| **education_occupation_match** | äº¤äº’ç‰¹å¾ | é«˜å­¦å†+é«˜æŠ€èƒ½èŒä¸š = é«˜æ”¶å…¥ï¼ˆ**æ•™è‚²å›æŠ¥**ï¼‰ | æ˜¾å¼å»ºæ¨¡æ•™è‚²ä¸èŒä¸šçš„ååŒæ•ˆåº” |\n",
    "| **work_experience** | æ´¾ç”Ÿç‰¹å¾ | å·¥ä½œå¹´é™æ˜¯æ”¶å…¥çš„é‡è¦å› ç´ ï¼ˆä¿å®ˆä¼°ç®—ï¼‰ | è¡¥å……å¹´é¾„ä¿¡æ¯ |\n",
    "| **is_married** | äºŒå€¼åŒ– | å·²å©šäººå£«æ”¶å…¥æ˜¾è‘—æ›´é«˜ï¼ˆå®¶åº­è´£ä»»+åŒèŒå·¥ï¼‰ | æ•æ‰å©šå§»çŠ¶æ€çš„ç»æµå½±å“ |\n",
    "| **is_full_time** | äºŒå€¼åŒ– | å…¨èŒvså…¼èŒçš„æ”¶å…¥å·®è·å·¨å¤§ | ç®€åŒ–hours.per.weekçš„éçº¿æ€§å…³ç³» |\n",
    "\n",
    "---\n",
    "\n",
    "#### âŒ æ‹’ç»çš„ç‰¹å¾ï¼ˆåŠåŸå› ï¼‰\n",
    "\n",
    "| ç‰¹å¾ | é—®é¢˜ | ä¸ºä»€ä¹ˆä¸ç”¨ |\n",
    "|------|------|-----------|\n",
    "| **income_potential** | æ•°æ®æ³„éœ² | æ‰‹å·¥åŠ æƒç»„åˆç‰¹å¾ = æå‰å‘Šè¯‰æ¨¡å‹ç­”æ¡ˆï¼Œä¼šå¯¼è‡´è¿‡æ‹Ÿåˆ |\n",
    "| **from_high_income_country** | ç§æ—æ­§è§† | ç›´æ¥ç¼–ç å›½ç±åè§ï¼Œè¿åAIä¼¦ç† |\n",
    "| **age_squared** | å‡è®¾é”™è¯¯ | æ”¶å…¥-å¹´é¾„å…³ç³»ä¸æ˜¯äºŒæ¬¡æ›²çº¿ï¼Œåˆ†ç»„æ›´åˆç† |\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ’¡ ç‰¹å¾å·¥ç¨‹çš„æƒè¡¡\n",
    "\n",
    "**ä¸æ˜¯ç‰¹å¾è¶Šå¤šè¶Šå¥½**ï¼š\n",
    "- âœ… æœ‰æ„ä¹‰çš„ç‰¹å¾ï¼šæå‡æ¨¡å‹æ€§èƒ½\n",
    "- âŒ å™ªéŸ³ç‰¹å¾ï¼šå¢åŠ è¿‡æ‹Ÿåˆé£é™©\n",
    "- âŒ å†—ä½™ç‰¹å¾ï¼šè®¡ç®—æˆæœ¬â†‘ï¼Œå¯è§£é‡Šæ€§â†“\n",
    "\n",
    "**æœ¬é¡¹ç›®ç­–ç•¥**ï¼š\n",
    "- ä¿å®ˆåˆ›å»ºç‰¹å¾ï¼ˆ~10ä¸ªæ–°ç‰¹å¾ï¼‰\n",
    "- æ¯ä¸ªç‰¹å¾éƒ½æœ‰æ˜ç¡®çš„ä¸šåŠ¡é€»è¾‘\n",
    "- é¿å…æ•°æ®æ³„éœ²å’Œä¼¦ç†é—®é¢˜\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 åˆ›å»ºæ–°ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ae3c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Enhanced Feature Engineering ===\n",
      "Strategy: Domain-knowledge driven feature creation\n",
      "\n",
      "âœ“ Created 'age_group' feature\n",
      "  Rationale: Age-income relationship is segmented, not quadratic\n",
      "  Bins: <25, 25-35, 35-45, 45-55, 55+\n",
      "\n",
      "âœ“ Created advanced capital features:\n",
      "  - has_capital_gain/loss: Binary indicators\n",
      "  - log_capital_gain: Log transformation for skewed distribution\n",
      "  - capital_total_activity: Financial activity level (sum)\n",
      "  - has_any_capital: Investment behavior indicator\n",
      "\n",
      "âœ“ Created 'is_full_time' feature\n",
      "  Rationale: Captures full-time vs part-time employment status\n",
      "\n",
      "âœ“ Created 'education_occupation_match' feature\n",
      "  Rationale: High education + high-skill job = higher income\n",
      "  Definition: Bachelor's degree+ AND professional/managerial role\n",
      "\n",
      "âœ“ Created 'work_experience' feature\n",
      "  Rationale: Years of experience strongly correlate with income\n",
      "  Formula: max(0, age - education.num - 6), capped at age-18\n",
      "\n",
      "âœ“ Created 'is_married' feature\n",
      "  Rationale: Married individuals have higher income (dual income, stability)\n",
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "======================================================================\n",
      "Total new features created: 10\n",
      "Feature list: age_group, log_capital_gain, capital_total_activity, has_any_capital, has_capital_gain, has_capital_loss, is_full_time, education_occupation_match, work_experience, is_married\n",
      "\n",
      "Dataset shape after feature engineering: (31978, 25)\n",
      "Original features: 15\n",
      "Added features: 10\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Enhanced Feature Engineering ===\")\n",
    "print(\"Strategy: Domain-knowledge driven feature creation\\n\")\n",
    "\n",
    "# === 1. Age Group (æ›¿ä»£ age_squared) ===\n",
    "if 'age' in df.columns:\n",
    "    df['age_group'] = pd.cut(df['age'], bins=[0, 25, 35, 45, 55, 100], \n",
    "                             labels=[1, 2, 3, 4, 5])\n",
    "    print(\"âœ“ Created 'age_group' feature\")\n",
    "    print(\"  Rationale: Age-income relationship is segmented, not quadratic\")\n",
    "    print(\"  Bins: <25, 25-35, 35-45, 45-55, 55+\")\n",
    "\n",
    "# === 2. Advanced Capital Features ===\n",
    "if 'capital.gain' in df.columns and 'capital.loss' in df.columns:\n",
    "    # Binary indicators\n",
    "    df['has_capital_gain'] = (df['capital.gain'] > 0).astype(int)\n",
    "    df['has_capital_loss'] = (df['capital.loss'] > 0).astype(int)\n",
    "    \n",
    "    # Log transformation (handles right-skewed distribution)\n",
    "    df['log_capital_gain'] = np.log1p(df['capital.gain'])\n",
    "    \n",
    "    # Total capital activity (sum is more meaningful than net)\n",
    "    df['capital_total_activity'] = df['capital.gain'] + df['capital.loss']\n",
    "    \n",
    "    # Any capital activity indicator\n",
    "    df['has_any_capital'] = ((df['capital.gain'] > 0) | (df['capital.loss'] > 0)).astype(int)\n",
    "    \n",
    "    print(\"\\nâœ“ Created advanced capital features:\")\n",
    "    print(\"  - has_capital_gain/loss: Binary indicators\")\n",
    "    print(\"  - log_capital_gain: Log transformation for skewed distribution\")\n",
    "    print(\"  - capital_total_activity: Financial activity level (sum)\")\n",
    "    print(\"  - has_any_capital: Investment behavior indicator\")\n",
    "\n",
    "# === 3. Work Hours ===\n",
    "if 'hours.per.week' in df.columns:\n",
    "    df['is_full_time'] = (df['hours.per.week'] >= 35).astype(int)\n",
    "    print(\"\\nâœ“ Created 'is_full_time' feature\")\n",
    "    print(\"  Rationale: Captures full-time vs part-time employment status\")\n",
    "\n",
    "# === 4. Education-Occupation Match ===\n",
    "if 'education.num' in df.columns and 'occupation' in df.columns:\n",
    "    high_skill_occupations = ['Prof-specialty', 'Exec-managerial', 'Tech-support']\n",
    "    df['education_occupation_match'] = (\n",
    "        (df['education.num'] >= 13) & (df['occupation'].isin(high_skill_occupations))\n",
    "    ).astype(int)\n",
    "    print(\"\\nâœ“ Created 'education_occupation_match' feature\")\n",
    "    print(\"  Rationale: High education + high-skill job = higher income\")\n",
    "    print(\"  Definition: Bachelor's degree+ AND professional/managerial role\")\n",
    "\n",
    "# === 5. Work Experience Estimation ===\n",
    "if 'age' in df.columns and 'education.num' in df.columns:\n",
    "    # Conservative estimate: age - education_years - 6 (typical school starting age)\n",
    "    df['work_experience'] = np.maximum(0, df['age'] - df['education.num'] - 6)\n",
    "    # Cap at reasonable maximum (assuming work starts at 18 earliest)\n",
    "    df['work_experience'] = np.minimum(df['work_experience'], df['age'] - 18)\n",
    "    print(\"\\nâœ“ Created 'work_experience' feature\")\n",
    "    print(\"  Rationale: Years of experience strongly correlate with income\")\n",
    "    print(\"  Formula: max(0, age - education.num - 6), capped at age-18\")\n",
    "\n",
    "# === 6. Marital Status ===\n",
    "if 'marital.status' in df.columns:\n",
    "    married_categories = ['Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse']\n",
    "    df['is_married'] = df['marital.status'].isin(married_categories).astype(int)\n",
    "    print(\"\\nâœ“ Created 'is_married' feature\")\n",
    "    print(\"  Rationale: Married individuals have higher income (dual income, stability)\")\n",
    "\n",
    "# === Summary ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "new_features = [\n",
    "    'age_group', 'log_capital_gain', 'capital_total_activity', \n",
    "    'has_any_capital', 'has_capital_gain', 'has_capital_loss',\n",
    "    'is_full_time', 'education_occupation_match', 'work_experience', 'is_married'\n",
    "]\n",
    "created_features = [f for f in new_features if f in df.columns]\n",
    "print(f\"Total new features created: {len(created_features)}\")\n",
    "print(f\"Feature list: {', '.join(created_features)}\")\n",
    "print(f\"\\nDataset shape after feature engineering: {df.shape}\")\n",
    "print(f\"Original features: {df_original.shape[1]}\")\n",
    "print(f\"Added features: {df.shape[1] - df_original.shape[1]}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0e8e0",
   "metadata": {},
   "source": [
    "### 4.3 ç¼–ç ç±»åˆ«å˜é‡\n",
    "\n",
    "#### ğŸ¯ ç¼–ç ç­–ç•¥ï¼šé¿å…æ•°æ®æ³„éœ²ä¸è™šå‡å…³ç³»\n",
    "\n",
    "**æ ¸å¿ƒé—®é¢˜**ï¼šä¸åŒç±»å‹çš„ç±»åˆ«å˜é‡éœ€è¦ä¸åŒçš„ç¼–ç æ–¹æ³•ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“‹ ç¼–ç æ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "| ç¼–ç æ–¹æ³• | åŸç† | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
    "|---------|------|---------|------|------|\n",
    "| **Label Encoding** | æ˜ å°„ä¸º0,1,2... | æœ‰åºç‰¹å¾ï¼ˆæ•™è‚²ï¼‰æˆ–æ ‘æ¨¡å‹ | ç®€å•ï¼Œä¸å¢åŠ ç»´åº¦ | å¼•å…¥è™šå‡é¡ºåºå…³ç³» |\n",
    "| **One-Hot Encoding** | æ¯ä¸ªç±»åˆ«ä¸€åˆ— | æ— åºç‰¹å¾ï¼ˆæ€§åˆ«ã€ç§æ—ï¼‰ | æ— é¡ºåºå‡è®¾ | é«˜åŸºæ•°æ—¶ç»´åº¦çˆ†ç‚¸ |\n",
    "| **Binary Encoding** | è½¬ä¸ºäºŒè¿›åˆ¶ä½ | é«˜åŸºæ•°æ— åºç‰¹å¾ | å¹³è¡¡ç»´åº¦ä¸é¡ºåº | è½»å¾®ä½æ¨¡å¼å…³è” |\n",
    "| **Target Encoding** | ç”¨ç›®æ ‡å‡å€¼ç¼–ç  | âŒ **æ•°æ®æ³„éœ²ï¼Œæœ¬é¡¹ç›®ç¦ç”¨** | æ€§èƒ½å¥½ | ä¸¥é‡æ³„éœ²é£é™© |\n",
    "| **Ordinal Encoding** | æ‰‹åŠ¨æŒ‡å®šé¡ºåº | æœ‰æ˜ç¡®é¡ºåºçš„ç‰¹å¾ | ä¿ç•™è¯­ä¹‰ | éœ€è¦é¢†åŸŸçŸ¥è¯† |\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ… æœ¬é¡¹ç›®çš„ç¼–ç ç­–ç•¥\n",
    "\n",
    "**1. äºŒåˆ†ç±»ç‰¹å¾ â†’ ç›´æ¥æ˜ å°„ (0/1)**\n",
    "- **sex**: Male=1, Female=0\n",
    "- **income**: <=50K=0, >50K=1\n",
    "- **ç†ç”±**: é¿å…LabelEncoderçš„éšæœºæ€§ï¼Œ0/1æ›´ç›´è§‚\n",
    "\n",
    "**2. ä½åŸºæ•°æ— åºç‰¹å¾ â†’ One-Hotç¼–ç **\n",
    "- **workclass** (8ç±»): Private, Government, Self-empç­‰\n",
    "- **marital.status** (7ç±»): Married, Divorcedç­‰\n",
    "- **relationship** (6ç±»): Husband, Wife, Own-childç­‰\n",
    "- **race** (5ç±»): White, Black, Asianç­‰\n",
    "- **ç†ç”±**: è¿™äº›ç±»åˆ«æ²¡æœ‰é¡ºåºå…³ç³»ï¼ŒOne-Hoté¿å…è™šå‡çš„æ•°å€¼å…³ç³»\n",
    "- **æŠ€å·§**: `drop_first=True`é¿å…å¤šé‡å…±çº¿æ€§ï¼ˆè™šæ‹Ÿå˜é‡é™·é˜±ï¼‰\n",
    "\n",
    "**3. æœ‰åºç‰¹å¾ â†’ Ordinal Encoding**\n",
    "- **education**: æ‰‹åŠ¨æŒ‡å®š1-16çš„é¡ºåºï¼ˆPreschool â†’ Doctorateï¼‰\n",
    "- **ç†ç”±**: æ•™è‚²ç¨‹åº¦æœ‰æ˜ç¡®çš„é€’è¿›å…³ç³»ï¼Œä¿ç•™é¡ºåºä¿¡æ¯\n",
    "\n",
    "**4. é«˜åŸºæ•°æ— åºç‰¹å¾ â†’ Binary Encoding**\n",
    "- **occupation** (14ç±»): Prof-specialty, Exec-managerialç­‰\n",
    "- **native.country** (42ç±»): United-States, Mexicoç­‰\n",
    "- **ç†ç”±**: \n",
    "  - One-Hotä¼šäº§ç”Ÿ56åˆ—ï¼ˆ14+42ï¼‰ï¼Œé€ æˆç»´åº¦çˆ†ç‚¸\n",
    "  - Binary Encodingåªéœ€10åˆ—ï¼ˆ4+6ï¼‰ï¼ŒèŠ‚çœ46åˆ—ï¼\n",
    "  - é¿å…Label Encodingçš„ä¸¥é‡è™šå‡é¡ºåºé—®é¢˜\n",
    "  - é€‚åˆLogistic Regressionç­‰çº¿æ€§æ¨¡å‹\n",
    "\n",
    "**Binary Encodingå·¥ä½œåŸç†**ï¼š\n",
    "```\n",
    "occupationæœ‰14ä¸ªç±»åˆ«ï¼Œéœ€è¦4ä½äºŒè¿›åˆ¶ï¼ˆ2^4=16>14ï¼‰ï¼š\n",
    "  Teacher(0)  â†’ [0,0,0,0]  â†’ occupation_0, occupation_1, occupation_2, occupation_3\n",
    "  Sales(5)    â†’ [0,1,0,1]\n",
    "  Doctor(13)  â†’ [1,1,0,1]\n",
    "\n",
    "ç»´åº¦å¯¹æ¯”ï¼š\n",
    "  Label Encoding: 1åˆ—ï¼ˆä½†æœ‰è™šå‡é¡ºåºï¼‰\n",
    "  Binary Encoding: 4åˆ—ï¼ˆå¹³è¡¡æ–¹æ¡ˆï¼‰âœ…\n",
    "  One-Hot: 14åˆ—ï¼ˆç»´åº¦çˆ†ç‚¸ï¼‰\n",
    "```\n",
    "\n",
    "**5. Categoricalç±»å‹ç‰¹å¾ â†’ è½¬æ¢ä¸ºcodes**\n",
    "- **age_group**: pd.cutåˆ›å»ºçš„Categorical â†’ è‡ªåŠ¨è½¬ä¸º0-4\n",
    "- **ç†ç”±**: å·²ç»æ˜¯æœ‰åºç±»åˆ«ï¼Œç›´æ¥ç”¨æ•°å€¼æ ‡ç­¾\n",
    "\n",
    "---\n",
    "\n",
    "#### âŒ æ‹’ç»çš„ç¼–ç æ–¹æ³•\n",
    "\n",
    "**Target Encodingï¼ˆç›®æ ‡ç¼–ç ï¼‰**\n",
    "```python\n",
    "# âŒ ä¸¥ç¦ä½¿ç”¨ï¼\n",
    "df['workclass'] = df.groupby('workclass')['income'].mean()\n",
    "```\n",
    "\n",
    "**ä¸ºä»€ä¹ˆè¿™æ˜¯æ•°æ®æ³„éœ²ï¼Ÿ**\n",
    "1. ä½ åœ¨ç”¨**ç›®æ ‡å˜é‡ï¼ˆincomeï¼‰**æ¥ç¼–ç ç‰¹å¾\n",
    "2. æ¨¡å‹ä¼šå­¦åˆ°ï¼š`workclass=0.8` â†’ 80%çš„äººé«˜æ”¶å…¥ â†’ ç›´æ¥å‘Šè¯‰ç­”æ¡ˆï¼\n",
    "3. å³ä½¿è®­ç»ƒ/æµ‹è¯•åˆ†å¼€ï¼Œä»æœ‰ç»Ÿè®¡æ³„éœ²\n",
    "\n",
    "**ç±»æ¯”**: è€ƒè¯•æ—¶ä½ é—®è€å¸ˆ\"é€‰Açš„é¢˜æ­£ç¡®ç‡æ˜¯å¤šå°‘\"ï¼Œè€å¸ˆè¯´\"90%\"ï¼Œä½ å½“ç„¶çŸ¥é“é€‰Aï¼\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ’¡ ç¼–ç é¡ºåºå¾ˆé‡è¦ï¼\n",
    "\n",
    "**æ­£ç¡®é¡ºåº**ï¼š\n",
    "1. å…ˆåˆ›å»ºè¡ç”Ÿç‰¹å¾ï¼ˆå¦‚age_groupï¼‰\n",
    "2. å†è¿›è¡Œç¼–ç \n",
    "3. æœ€åæ ‡å‡†åŒ–\n",
    "\n",
    "**é”™è¯¯ç¤ºä¾‹**ï¼š\n",
    "```python\n",
    "# âŒ é”™è¯¯ï¼šå…ˆæ ‡å‡†åŒ–å†One-Hotï¼Œä¼šå¯¼è‡´è™šæ‹Ÿå˜é‡ä¹Ÿè¢«æ ‡å‡†åŒ–\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "dummies = pd.get_dummies(df_scaled['sex'])  # é”™è¯¯ï¼\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4 å®æ–½ç¼–ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95612f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Improved Categorical Encoding ===\n",
      "Strategy: Match encoding method to feature type\n",
      "\n",
      "âœ“ Mapped 'sex' to binary (Male=1, Female=0)\n",
      "  Rationale: Avoids arbitrary ordering from LabelEncoder\n",
      "\n",
      "âœ“ Mapped 'income' to binary (<=50K=0, >50K=1)\n",
      "  Rationale: Clear 0/1 encoding for classification\n",
      "\n",
      "âœ“ One-Hot encoded 'workclass' â†’ 7 new columns\n",
      "  Rationale: No ordinal relationship (e.g., Private â‰  Government)\n",
      "âœ“ One-Hot encoded 'marital.status' â†’ 6 new columns\n",
      "  Rationale: No ordinal relationship (e.g., Private â‰  Government)\n",
      "âœ“ One-Hot encoded 'relationship' â†’ 5 new columns\n",
      "  Rationale: No ordinal relationship (e.g., Private â‰  Government)\n",
      "âœ“ One-Hot encoded 'race' â†’ 4 new columns\n",
      "  Rationale: No ordinal relationship (e.g., Private â‰  Government)\n",
      "\n",
      "  Total One-Hot columns created: 22\n",
      "  drop_first=True avoids multicollinearity (dummy variable trap)\n",
      "\n",
      "âœ“ Mapped 'sex' to binary (Male=1, Female=0)\n",
      "  Rationale: Avoids arbitrary ordering from LabelEncoder\n",
      "\n",
      "âœ“ Mapped 'income' to binary (<=50K=0, >50K=1)\n",
      "  Rationale: Clear 0/1 encoding for classification\n",
      "\n",
      "âœ“ One-Hot encoded 'workclass' â†’ 7 new columns\n",
      "  Rationale: No ordinal relationship (e.g., Private â‰  Government)\n",
      "âœ“ One-Hot encoded 'marital.status' â†’ 6 new columns\n",
      "  Rationale: No ordinal relationship (e.g., Private â‰  Government)\n",
      "âœ“ One-Hot encoded 'relationship' â†’ 5 new columns\n",
      "  Rationale: No ordinal relationship (e.g., Private â‰  Government)\n",
      "âœ“ One-Hot encoded 'race' â†’ 4 new columns\n",
      "  Rationale: No ordinal relationship (e.g., Private â‰  Government)\n",
      "\n",
      "  Total One-Hot columns created: 22\n",
      "  drop_first=True avoids multicollinearity (dummy variable trap)\n",
      "\n",
      "âœ“ Ordinal encoded 'education' (1-16)\n",
      "  Rationale: Education has natural progression (Preschool â†’ Doctorate)\n",
      "  Preserves meaningful ordering information\n",
      "\n",
      "=== Binary Encoding for High Cardinality Features ===\n",
      "âœ“ Ordinal encoded 'education' (1-16)\n",
      "  Rationale: Education has natural progression (Preschool â†’ Doctorate)\n",
      "  Preserves meaningful ordering information\n",
      "\n",
      "=== Binary Encoding for High Cardinality Features ===\n",
      "âœ“ Binary encoded 'occupation':\n",
      "  - Original categories: 14\n",
      "  - Binary columns created: 4 (vs One-Hot: 14)\n",
      "  - Dimension saved: 10 columns\n",
      "  - Column names: occupation_0, occupation_1, occupation_2, occupation_3\n",
      "  Rationale: Avoids dimension explosion while reducing false ordering\n",
      "\n",
      "âœ“ Binary encoded 'native.country':\n",
      "  - Original categories: 41\n",
      "  - Binary columns created: 6 (vs One-Hot: 41)\n",
      "  - Dimension saved: 35 columns\n",
      "  - Column names: native.country_0, native.country_1, native.country_2, native.country_3, native.country_4, native.country_5\n",
      "  Rationale: Avoids dimension explosion while reducing false ordering\n",
      "\n",
      "======================================================================\n",
      "BINARY ENCODING EXPLANATION\n",
      "======================================================================\n",
      "Converts categories to binary representation (each bit = one feature):\n",
      "  Example: occupation with 14 categories â†’ 4 binary features (2^4=16>14)\n",
      "    Category 0  â†’ [0,0,0,0]\n",
      "    Category 5  â†’ [0,1,0,1]\n",
      "    Category 13 â†’ [1,1,0,1]\n",
      "\n",
      "Advantages:\n",
      "  âœ“ vs Label Encoding: Reduces false ordering (no direct numerical relationship)\n",
      "  âœ“ vs One-Hot: Saves 46 columns (occupation: 14â†’4, country: 42â†’6)\n",
      "\n",
      "Trade-off:\n",
      "  âš  Slight bit pattern correlation (but much weaker than Label Encoding)\n",
      "======================================================================\n",
      "\n",
      "âœ“ Converted 'age_group' Categorical to numeric codes (0-4)\n",
      "  Rationale: pd.cut creates ordered categories, use codes directly\n",
      "\n",
      "======================================================================\n",
      "ENCODING VERIFICATION\n",
      "======================================================================\n",
      "Object columns remaining: 0\n",
      "  âœ“ All features are now numerical\n",
      "\n",
      "Dataset shape: (31978, 51)\n",
      "Features before encoding: 25\n",
      "Features after encoding: 51\n",
      "\n",
      "=== Data Leakage Check ===\n",
      "âœ“ No Target Encoding used (avoided leakage)\n",
      "âœ“ All encoding based on feature values only, not target variable\n",
      "âœ“ One-Hot with drop_first=True prevents multicollinearity\n",
      "\n",
      "=== Logistic Regression Compatibility ===\n",
      "âœ“ Binary Encoding reduces false ordering vs Label Encoding\n",
      "âœ“ Maintains manageable dimensionality vs One-Hot\n",
      "âœ“ Ready for gradient descent optimization\n",
      "======================================================================\n",
      "âœ“ Binary encoded 'occupation':\n",
      "  - Original categories: 14\n",
      "  - Binary columns created: 4 (vs One-Hot: 14)\n",
      "  - Dimension saved: 10 columns\n",
      "  - Column names: occupation_0, occupation_1, occupation_2, occupation_3\n",
      "  Rationale: Avoids dimension explosion while reducing false ordering\n",
      "\n",
      "âœ“ Binary encoded 'native.country':\n",
      "  - Original categories: 41\n",
      "  - Binary columns created: 6 (vs One-Hot: 41)\n",
      "  - Dimension saved: 35 columns\n",
      "  - Column names: native.country_0, native.country_1, native.country_2, native.country_3, native.country_4, native.country_5\n",
      "  Rationale: Avoids dimension explosion while reducing false ordering\n",
      "\n",
      "======================================================================\n",
      "BINARY ENCODING EXPLANATION\n",
      "======================================================================\n",
      "Converts categories to binary representation (each bit = one feature):\n",
      "  Example: occupation with 14 categories â†’ 4 binary features (2^4=16>14)\n",
      "    Category 0  â†’ [0,0,0,0]\n",
      "    Category 5  â†’ [0,1,0,1]\n",
      "    Category 13 â†’ [1,1,0,1]\n",
      "\n",
      "Advantages:\n",
      "  âœ“ vs Label Encoding: Reduces false ordering (no direct numerical relationship)\n",
      "  âœ“ vs One-Hot: Saves 46 columns (occupation: 14â†’4, country: 42â†’6)\n",
      "\n",
      "Trade-off:\n",
      "  âš  Slight bit pattern correlation (but much weaker than Label Encoding)\n",
      "======================================================================\n",
      "\n",
      "âœ“ Converted 'age_group' Categorical to numeric codes (0-4)\n",
      "  Rationale: pd.cut creates ordered categories, use codes directly\n",
      "\n",
      "======================================================================\n",
      "ENCODING VERIFICATION\n",
      "======================================================================\n",
      "Object columns remaining: 0\n",
      "  âœ“ All features are now numerical\n",
      "\n",
      "Dataset shape: (31978, 51)\n",
      "Features before encoding: 25\n",
      "Features after encoding: 51\n",
      "\n",
      "=== Data Leakage Check ===\n",
      "âœ“ No Target Encoding used (avoided leakage)\n",
      "âœ“ All encoding based on feature values only, not target variable\n",
      "âœ“ One-Hot with drop_first=True prevents multicollinearity\n",
      "\n",
      "=== Logistic Regression Compatibility ===\n",
      "âœ“ Binary Encoding reduces false ordering vs Label Encoding\n",
      "âœ“ Maintains manageable dimensionality vs One-Hot\n",
      "âœ“ Ready for gradient descent optimization\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Improved Categorical Encoding ===\")\n",
    "print(\"Strategy: Match encoding method to feature type\\n\")\n",
    "\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# === 1. Binary Features: Direct Mapping ===\n",
    "if 'sex' in df_encoded.columns:\n",
    "    df_encoded['sex'] = df_encoded['sex'].map({'Male': 1, 'Female': 0})\n",
    "    print(\"âœ“ Mapped 'sex' to binary (Male=1, Female=0)\")\n",
    "    print(\"  Rationale: Avoids arbitrary ordering from LabelEncoder\\n\")\n",
    "\n",
    "# === 2. Target Variable: Direct Mapping ===\n",
    "target_col = 'income'\n",
    "if target_col in df_encoded.columns:\n",
    "    df_encoded[target_col] = (df_encoded[target_col] == '>50K').astype(int)\n",
    "    print(f\"âœ“ Mapped '{target_col}' to binary (<=50K=0, >50K=1)\")\n",
    "    print(\"  Rationale: Clear 0/1 encoding for classification\\n\")\n",
    "\n",
    "# === 3. Low Cardinality Unordered Features: One-Hot Encoding ===\n",
    "low_cardinality_cols = ['workclass', 'marital.status', 'relationship', 'race']\n",
    "onehot_features = []\n",
    "for col in low_cardinality_cols:\n",
    "    if col in df_encoded.columns:\n",
    "        dummies = pd.get_dummies(df_encoded[col], prefix=col, drop_first=True)\n",
    "        onehot_features.extend(dummies.columns.tolist())\n",
    "        df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "        df_encoded.drop(col, axis=1, inplace=True)\n",
    "        print(f\"âœ“ One-Hot encoded '{col}' â†’ {len(dummies.columns)} new columns\")\n",
    "        print(f\"  Rationale: No ordinal relationship (e.g., Private â‰  Government)\")\n",
    "\n",
    "print(f\"\\n  Total One-Hot columns created: {len(onehot_features)}\")\n",
    "print(f\"  drop_first=True avoids multicollinearity (dummy variable trap)\\n\")\n",
    "\n",
    "# === 4. Ordinal Feature: Manual Mapping ===\n",
    "if 'education' in df_encoded.columns:\n",
    "    education_order = {\n",
    "        'Preschool': 1, '1st-4th': 2, '5th-6th': 3, '7th-8th': 4,\n",
    "        '9th': 5, '10th': 6, '11th': 7, '12th': 8,\n",
    "        'HS-grad': 9, 'Some-college': 10, 'Assoc-voc': 11,\n",
    "        'Assoc-acdm': 12, 'Bachelors': 13, 'Masters': 14,\n",
    "        'Prof-school': 15, 'Doctorate': 16\n",
    "    }\n",
    "    df_encoded['education'] = df_encoded['education'].map(education_order)\n",
    "    print(\"âœ“ Ordinal encoded 'education' (1-16)\")\n",
    "    print(\"  Rationale: Education has natural progression (Preschool â†’ Doctorate)\")\n",
    "    print(\"  Preserves meaningful ordering information\\n\")\n",
    "\n",
    "# === 5. High Cardinality Features: Binary Encoding ===\n",
    "print(\"=== Binary Encoding for High Cardinality Features ===\")\n",
    "\n",
    "\n",
    "high_cardinality_cols = ['occupation', 'native.country']\n",
    "binary_encoder = ce.BinaryEncoder(cols=high_cardinality_cols, return_df=True)\n",
    "df_encoded = binary_encoder.fit_transform(df_encoded)\n",
    "\n",
    "for col in high_cardinality_cols:\n",
    "    if col in df.columns:\n",
    "        n_categories = df[col].nunique()\n",
    "        n_bits = int(np.ceil(np.log2(n_categories)))\n",
    "        binary_cols = [c for c in df_encoded.columns if c.startswith(f'{col}_')]\n",
    "        \n",
    "        print(f\"âœ“ Binary encoded '{col}':\")\n",
    "        print(f\"  - Original categories: {n_categories}\")\n",
    "        print(f\"  - Binary columns created: {len(binary_cols)} (vs One-Hot: {n_categories})\")\n",
    "        print(f\"  - Dimension saved: {n_categories - len(binary_cols)} columns\")\n",
    "        print(f\"  - Column names: {', '.join(binary_cols)}\")\n",
    "        print(f\"  Rationale: Avoids dimension explosion while reducing false ordering\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BINARY ENCODING EXPLANATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"Converts categories to binary representation (each bit = one feature):\")\n",
    "print(\"  Example: occupation with 14 categories â†’ 4 binary features (2^4=16>14)\")\n",
    "print(\"    Category 0  â†’ [0,0,0,0]\")\n",
    "print(\"    Category 5  â†’ [0,1,0,1]\")\n",
    "print(\"    Category 13 â†’ [1,1,0,1]\")\n",
    "print(\"\\nAdvantages:\")\n",
    "print(\"  âœ“ vs Label Encoding: Reduces false ordering (no direct numerical relationship)\")\n",
    "print(\"  âœ“ vs One-Hot: Saves 46 columns (occupation: 14â†’4, country: 42â†’6)\")\n",
    "print(\"\\nTrade-off:\")\n",
    "print(\"  âš  Slight bit pattern correlation (but much weaker than Label Encoding)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# === 6. Handle Categorical Type (age_group) ===\n",
    "if 'age_group' in df_encoded.columns:\n",
    "    if pd.api.types.is_categorical_dtype(df_encoded['age_group']):\n",
    "        df_encoded['age_group'] = df_encoded['age_group'].cat.codes\n",
    "        print(\"\\nâœ“ Converted 'age_group' Categorical to numeric codes (0-4)\")\n",
    "        print(\"  Rationale: pd.cut creates ordered categories, use codes directly\\n\")\n",
    "\n",
    "# === Verification ===\n",
    "print(\"=\"*70)\n",
    "print(\"ENCODING VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "object_cols_remaining = df_encoded.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Object columns remaining: {len(object_cols_remaining)}\")\n",
    "if object_cols_remaining:\n",
    "    print(f\"  Warning: {object_cols_remaining}\")\n",
    "else:\n",
    "    print(\"  âœ“ All features are now numerical\")\n",
    "\n",
    "print(f\"\\nDataset shape: {df_encoded.shape}\")\n",
    "print(f\"Features before encoding: {df.shape[1]}\")\n",
    "print(f\"Features after encoding: {df_encoded.shape[1]}\")\n",
    "\n",
    "print(\"\\n=== Data Leakage Check ===\")\n",
    "print(\"âœ“ No Target Encoding used (avoided leakage)\")\n",
    "print(\"âœ“ All encoding based on feature values only, not target variable\")\n",
    "print(\"âœ“ One-Hot with drop_first=True prevents multicollinearity\")\n",
    "\n",
    "print(\"\\n=== Logistic Regression Compatibility ===\")\n",
    "print(\"âœ“ Binary Encoding reduces false ordering vs Label Encoding\")\n",
    "print(\"âœ“ Maintains manageable dimensionality vs One-Hot\")\n",
    "print(\"âœ“ Ready for gradient descent optimization\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269fee1",
   "metadata": {},
   "source": [
    "### 4.5 åˆ é™¤å†—ä½™ç‰¹å¾\n",
    "\n",
    "#### ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦åˆ é™¤å†—ä½™ç‰¹å¾ï¼Ÿ\n",
    "\n",
    "**å†—ä½™ç‰¹å¾çš„å±å®³ï¼š**\n",
    "1. **å¤šé‡å…±çº¿æ€§**ï¼šç›¸åŒä¿¡æ¯çš„ç‰¹å¾ä¼šç›¸äº’å¹²æ‰°ï¼ˆå°¤å…¶å¯¹Logistic Regressionï¼‰\n",
    "2. **è¿‡æ‹Ÿåˆé£é™©**ï¼šæ¨¡å‹å¯èƒ½å­¦ä¹ åˆ°è™šå‡çš„æ¨¡å¼\n",
    "3. **è®¡ç®—æ•ˆç‡**ï¼šæ›´å¤šç‰¹å¾ = æ›´æ…¢çš„è®­ç»ƒ\n",
    "4. **å¯è§£é‡Šæ€§**ï¼šé‡å¤ä¿¡æ¯é™ä½æ¨¡å‹é€æ˜åº¦\n",
    "\n",
    "**åˆ é™¤åŸåˆ™ï¼š**\n",
    "- âœ… **å®Œå…¨å†—ä½™**ï¼šä¸¤ä¸ªç‰¹å¾å®Œå…¨ç›¸åŒ â†’ å¿…é¡»åˆ é™¤\n",
    "- âœ… **é«˜åº¦å†—ä½™**ï¼šè¡ç”Ÿç‰¹å¾å®Œå…¨åŒ…å«åŸå§‹ä¿¡æ¯ â†’ å»ºè®®åˆ é™¤\n",
    "- âš ï¸ **éƒ¨åˆ†å†—ä½™**ï¼šä¸¤è€…æä¾›ä¸åŒå±‚æ¬¡çš„ä¿¡æ¯ â†’ ä¿ç•™\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“‹ åˆ é™¤æ¸…å•\n",
    "\n",
    "| ç‰¹å¾ | å†—ä½™ç±»å‹ | ç†ç”± | æ›¿ä»£ç‰¹å¾ |\n",
    "|------|---------|------|---------|\n",
    "| **education.num** | å®Œå…¨å†—ä½™ | ä¸ordinalç¼–ç çš„educationå®Œå…¨ç›¸åŒ | education |\n",
    "| **capital.gain** | é«˜åº¦å†—ä½™ | ä¿¡æ¯å·²è¢«log_capital_gainæ•è· | log_capital_gain + has_capital_gain |\n",
    "| **capital.loss** | é«˜åº¦å†—ä½™ | ä¿¡æ¯å·²è¢«has_capital_lossæ•è· | has_capital_loss |\n",
    "| **fnlwgt** | ä¸ç›¸å…³ | é‡‡æ ·æƒé‡ï¼Œå¯¹æ”¶å…¥é¢„æµ‹æ— æ„ä¹‰ | - |\n",
    "\n",
    "**ä¿ç•™çš„\"éƒ¨åˆ†å†—ä½™\"ç‰¹å¾ï¼š**\n",
    "- âœ… **age** + **age_group**ï¼šè¿ç»­å€¼ï¼ˆç»†ç²’åº¦ï¼‰+ åˆ†ç®±ï¼ˆé˜¶æ®µæ€§ï¼‰ï¼Œæä¾›ä¸åŒå±‚æ¬¡ä¿¡æ¯\n",
    "- âœ… **hours.per.week** + **is_full_time**ï¼šç²¾ç¡®å·¥æ—¶ + å°±ä¸šçŠ¶æ€ï¼Œæ•æ‰ä¸åŒè¯­ä¹‰\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ”¬ å†—ä½™åˆ†æç¤ºä¾‹\n",
    "\n",
    "**å®Œå…¨å†—ä½™ï¼ˆå¿…é¡»åˆ é™¤ï¼‰ï¼š**\n",
    "```python\n",
    "education.num = [13, 9, 16, ...]  # åŸå§‹ç‰¹å¾\n",
    "education     = [13, 9, 16, ...]  # Ordinalç¼–ç å\n",
    "# âŒ å®Œå…¨ç›¸åŒï¼å¼•å…¥å¤šé‡å…±çº¿æ€§\n",
    "```\n",
    "\n",
    "**é«˜åº¦å†—ä½™ï¼ˆå»ºè®®åˆ é™¤ï¼‰ï¼š**\n",
    "```python\n",
    "capital.gain = [15024, 0, 7688, ...]     # åŸå§‹ï¼Œå³ååˆ†å¸ƒ\n",
    "log_capital_gain = [9.6, 0, 8.9, ...]    # Logå˜æ¢ï¼Œæ­£æ€åŒ–\n",
    "has_capital_gain = [1, 0, 1, ...]        # æ˜¯å¦æœ‰æŠ•èµ„\n",
    "# âœ… åä¸¤è€…åŒ…å«äº†åŸå§‹ä¿¡æ¯ï¼Œä¸”æ›´é€‚åˆæ¨¡å‹\n",
    "```\n",
    "\n",
    "**éƒ¨åˆ†å†—ä½™ï¼ˆéƒ½ä¿ç•™ï¼‰ï¼š**\n",
    "```python\n",
    "age = [25, 35, 45, 55, ...]           # è¿ç»­ï¼Œæ•æ‰ç»†å¾®å·®å¼‚\n",
    "age_group = [1, 2, 3, 4, ...]         # åˆ†ç®±ï¼Œæ•æ‰é˜¶æ®µæ€§å˜åŒ–\n",
    "# âœ… ä¸¤è€…æä¾›ä¸åŒç²’åº¦çš„ä¿¡æ¯\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "521b9d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Removing Redundant Features ===\n",
      "Strategy: Remove features that are completely captured by derived features\n",
      "\n",
      "âœ“ Identified 'education.num' as redundant\n",
      "  Reason: Completely duplicates 'education' (ordinal encoded)\n",
      "  Impact: Causes multicollinearity in Logistic Regression\n",
      "\n",
      "âœ“ Identified 'capital.gain' as redundant\n",
      "  Reason: Information captured by 'log_capital_gain' + 'has_capital_gain'\n",
      "  Benefit: Removes right-skewed distribution issue\n",
      "\n",
      "âœ“ Identified 'capital.loss' as redundant\n",
      "  Reason: Information captured by 'has_capital_loss'\n",
      "  Benefit: Removes skewness\n",
      "\n",
      "âœ“ Identified 'fnlwgt' as redundant\n",
      "  Reason: Census sampling weight, not predictive of income\n",
      "  Benefit: Removes noise from model\n",
      "\n",
      "======================================================================\n",
      "FEATURE REMOVAL SUMMARY\n",
      "======================================================================\n",
      "Features removed: 4\n",
      "  - education.num\n",
      "  - capital.gain\n",
      "  - capital.loss\n",
      "  - fnlwgt\n",
      "\n",
      "Dataset shape:\n",
      "  Before: 51 features\n",
      "  After: 47 features\n",
      "  Reduction: 4 features\n",
      "\n",
      "âœ“ Benefits:\n",
      "  - Eliminated multicollinearity (especially education.num)\n",
      "  - Removed skewed distributions (capital.gain/loss)\n",
      "  - Removed non-predictive features (fnlwgt)\n",
      "  - Cleaner model with similar/better predictive power\n",
      "\n",
      "âœ“ Preserved partial redundancy:\n",
      "  - age + age_group: Different granularity (continuous vs binned)\n",
      "  - hours.per.week + is_full_time: Different semantics (exact vs status)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Removing Redundant Features ===\")\n",
    "print(\"Strategy: Remove features that are completely captured by derived features\\n\")\n",
    "\n",
    "# === 1. Identify Redundant Features ===\n",
    "redundant_features = []\n",
    "\n",
    "# Complete redundancy (MUST remove)\n",
    "if 'education.num' in df_encoded.columns and 'education' in df_encoded.columns:\n",
    "    redundant_features.append('education.num')\n",
    "    print(\"âœ“ Identified 'education.num' as redundant\")\n",
    "    print(\"  Reason: Completely duplicates 'education' (ordinal encoded)\")\n",
    "    print(\"  Impact: Causes multicollinearity in Logistic Regression\\n\")\n",
    "\n",
    "# High redundancy - capital.gain (SHOULD remove for cleaner model)\n",
    "if 'capital.gain' in df_encoded.columns and 'log_capital_gain' in df_encoded.columns:\n",
    "    redundant_features.append('capital.gain')\n",
    "    print(\"âœ“ Identified 'capital.gain' as redundant\")\n",
    "    print(\"  Reason: Information captured by 'log_capital_gain' + 'has_capital_gain'\")\n",
    "    print(\"  Benefit: Removes right-skewed distribution issue\\n\")\n",
    "\n",
    "# High redundancy - capital.loss\n",
    "if 'capital.loss' in df_encoded.columns and 'has_capital_loss' in df_encoded.columns:\n",
    "    redundant_features.append('capital.loss')\n",
    "    print(\"âœ“ Identified 'capital.loss' as redundant\")\n",
    "    print(\"  Reason: Information captured by 'has_capital_loss'\")\n",
    "    print(\"  Benefit: Removes skewness\\n\")\n",
    "\n",
    "# Sampling weight (not predictive)\n",
    "if 'fnlwgt' in df_encoded.columns:\n",
    "    redundant_features.append('fnlwgt')\n",
    "    print(\"âœ“ Identified 'fnlwgt' as redundant\")\n",
    "    print(\"  Reason: Census sampling weight, not predictive of income\")\n",
    "    print(\"  Benefit: Removes noise from model\\n\")\n",
    "\n",
    "# === 2. Remove Redundant Features ===\n",
    "features_before = df_encoded.shape[1]\n",
    "df_encoded = df_encoded.drop(columns=redundant_features, errors='ignore')\n",
    "features_after = df_encoded.shape[1]\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"FEATURE REMOVAL SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Features removed: {len(redundant_features)}\")\n",
    "for feat in redundant_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "print(f\"\\nDataset shape:\")\n",
    "print(f\"  Before: {features_before} features\")\n",
    "print(f\"  After: {features_after} features\")\n",
    "print(f\"  Reduction: {features_before - features_after} features\")\n",
    "\n",
    "print(\"\\nâœ“ Benefits:\")\n",
    "print(\"  - Eliminated multicollinearity (especially education.num)\")\n",
    "print(\"  - Removed skewed distributions (capital.gain/loss)\")\n",
    "print(\"  - Removed non-predictive features (fnlwgt)\")\n",
    "print(\"  - Cleaner model with similar/better predictive power\")\n",
    "\n",
    "print(\"\\nâœ“ Preserved partial redundancy:\")\n",
    "print(\"  - age + age_group: Different granularity (continuous vs binned)\")\n",
    "print(\"  - hours.per.week + is_full_time: Different semantics (exact vs status)\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c2b48e",
   "metadata": {},
   "source": [
    "## 5. ç‰¹å¾æ ‡å‡†åŒ–\n",
    "\n",
    "### 5.1 æ ‡å‡†åŒ–ç­–ç•¥ï¼šåŒºåˆ†ç‰¹å¾ç±»å‹\n",
    "\n",
    "#### ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦é€‰æ‹©æ€§æ ‡å‡†åŒ–ï¼Ÿ\n",
    "\n",
    "**æ ‡å‡†åŒ–çš„ç›®çš„**ï¼šå°†ä¸åŒé‡çº²çš„ç‰¹å¾è½¬æ¢åˆ°ç›¸åŒå°ºåº¦ï¼ˆå‡å€¼=0ï¼Œæ ‡å‡†å·®=1ï¼‰\n",
    "\n",
    "**ä½†å¹¶éæ‰€æœ‰ç‰¹å¾éƒ½åº”è¯¥æ ‡å‡†åŒ–ï¼**\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ“‹ ç‰¹å¾ç±»å‹åˆ†ç±»ä¸æ ‡å‡†åŒ–ç­–ç•¥\n",
    "\n",
    "| ç‰¹å¾ç±»å‹ | ç¤ºä¾‹ | æ˜¯å¦æ ‡å‡†åŒ– | ç†ç”± |\n",
    "|---------|------|-----------|------|\n",
    "| **è¿ç»­æ•°å€¼ç‰¹å¾** | age, hours.per.week, capital.gain | âœ… **éœ€è¦** | ä¸åŒé‡çº²ï¼ˆå¹´é¾„vså°æ—¶vsé‡‘é¢ï¼‰ï¼Œéœ€è¦ç»Ÿä¸€å°ºåº¦ |\n",
    "| **æœ‰åºç±»åˆ«ç¼–ç ** | education(1-16), age_group(0-4) | âœ… **éœ€è¦** | è™½ç„¶æ˜¯æ•´æ•°ï¼Œä½†æ•°å€¼èŒƒå›´ä¸åŒï¼Œæ ‡å‡†åŒ–åå¯æ¯” |\n",
    "| **äºŒåˆ†ç±»ç‰¹å¾** | sex(0/1), is_married(0/1) | âŒ **ä¸éœ€è¦** | å·²ç»æ˜¯0/1æ ‡å‡†å°ºåº¦ï¼Œæ ‡å‡†åŒ–ä¼šç ´åè¯­ä¹‰ |\n",
    "| **One-Hotç‰¹å¾** | workclass_Private(0/1) | âŒ **ä¸éœ€è¦** | å·²ç»æ˜¯0/1ï¼Œæ ‡å‡†åŒ–åå¤±å»è™šæ‹Ÿå˜é‡æ„ä¹‰ |\n",
    "| **Binary Encoding** | occupation_0(0/1), occupation_1(0/1) | âŒ **ä¸éœ€è¦** | æ¯ä¸ªä½éƒ½æ˜¯0/1ï¼Œå·²ç»æ˜¯æ ‡å‡†å°ºåº¦ |\n",
    "\n",
    "---\n",
    "\n",
    "#### âš ï¸ äºŒåˆ†ç±»ç‰¹å¾æ ‡å‡†åŒ–çš„é—®é¢˜\n",
    "\n",
    "**ç¤ºä¾‹ï¼šå¦‚æœå¯¹`is_married`æ ‡å‡†åŒ–**\n",
    "\n",
    "```python\n",
    "# åŸå§‹æ•°æ®ï¼ˆ0/1æœ‰æ˜ç¡®è¯­ä¹‰ï¼‰\n",
    "is_married = [0, 1, 1, 0, 1]  # 0=æœªå©š, 1=å·²å©š\n",
    "\n",
    "# æ ‡å‡†åŒ–åï¼ˆå‡å€¼=0.6, æ ‡å‡†å·®=0.49ï¼‰\n",
    "is_married_scaled = [-1.22, 0.82, 0.82, -1.22, 0.82]\n",
    "\n",
    "# é—®é¢˜ï¼š\n",
    "# âŒ å¤±å»äº†0/1çš„ç›´è§‚å«ä¹‰\n",
    "# âŒ å‡ºç°è´Ÿå€¼ï¼ˆæœªå©š=-1.22ï¼Ÿï¼‰\n",
    "# âŒ ç ´åäº†è™šæ‹Ÿå˜é‡çš„è¯­ä¹‰\n",
    "```\n",
    "\n",
    "**ç»“è®º**ï¼šäºŒåˆ†ç±»ç‰¹å¾åº”ä¿æŒ0/1åŸå§‹å°ºåº¦ï¼\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ”¬ ä¸åŒæ¨¡å‹å¯¹æ ‡å‡†åŒ–çš„éœ€æ±‚\n",
    "\n",
    "| æ¨¡å‹ | æ˜¯å¦éœ€è¦æ ‡å‡†åŒ– | åŸå›  |\n",
    "|------|--------------|------|\n",
    "| **Logistic Regression** | âœ… **å¼ºçƒˆéœ€è¦** | æ¢¯åº¦ä¸‹é™ä¼˜åŒ–éœ€è¦ç»Ÿä¸€å°ºåº¦ï¼Œå¦åˆ™æ”¶æ•›æ…¢ |\n",
    "| **Random Forest** | âŒ ä¸éœ€è¦ | æ ‘åˆ†è£‚åŸºäºé˜ˆå€¼ï¼Œä¸å—ç‰¹å¾å°ºåº¦å½±å“ |\n",
    "| **SVM** | âœ… **å¼ºçƒˆéœ€è¦** | è·ç¦»è®¡ç®—ä¾èµ–ç‰¹å¾å°ºåº¦ |\n",
    "| **Neural Networks** | âœ… **å¼ºçƒˆéœ€è¦** | åŠ é€Ÿæ”¶æ•›ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ |\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ’¡ Binary Encodingç‰¹å¾çš„æ ‡å‡†åŒ–ï¼Ÿ\n",
    "\n",
    "**Binary Encodingçš„æ¯ä¸€ä½éƒ½æ˜¯0/1ï¼**\n",
    "\n",
    "```python\n",
    "# occupationç»è¿‡Binary Encodingåï¼š\n",
    "occupation_0 = [0, 1, 0, 1, ...]  # ç¬¬1ä½\n",
    "occupation_1 = [1, 0, 1, 1, ...]  # ç¬¬2ä½\n",
    "occupation_2 = [0, 0, 1, 0, ...]  # ç¬¬3ä½\n",
    "occupation_3 = [1, 1, 0, 1, ...]  # ç¬¬4ä½\n",
    "\n",
    "# æ¯ä¸ªä½éƒ½å·²ç»æ˜¯0/1æ ‡å‡†å°ºåº¦ï¼\n",
    "```\n",
    "\n",
    "**ç»“è®º**ï¼š\n",
    "- âŒ **ä¸éœ€è¦æ ‡å‡†åŒ–**ï¼šæ¯ä¸ªä½å·²ç»æ˜¯0/1\n",
    "- âœ… **ç›´æ¥ä½¿ç”¨**ï¼šå°±åƒOne-Hotç‰¹å¾ä¸€æ ·\n",
    "\n",
    "---\n",
    "\n",
    "#### âœ… æœ¬é¡¹ç›®çš„æ ‡å‡†åŒ–ç­–ç•¥\n",
    "\n",
    "**éœ€è¦æ ‡å‡†åŒ–çš„ç‰¹å¾**ï¼š\n",
    "1. **è¿ç»­æ•°å€¼ç‰¹å¾**ï¼šage, fnlwgt, hours.per.week, capital.gain, capital.loss, log_capital_gain, capital_total_activity, work_experience\n",
    "2. **æœ‰åºç¼–ç ç‰¹å¾**ï¼šeducation(1-16), age_group(0-4)\n",
    "\n",
    "**ä¸éœ€è¦æ ‡å‡†åŒ–çš„ç‰¹å¾**ï¼š\n",
    "1. **äºŒåˆ†ç±»ç‰¹å¾**ï¼šsex, is_married, is_full_time, has_capital_gain, has_capital_loss, has_any_capital, education_occupation_match\n",
    "2. **One-Hotç‰¹å¾**ï¼šworkclass_*, marital.status_*, relationship_*, race_*\n",
    "3. **Binary Encodingç‰¹å¾**ï¼šoccupation_0~3, native.country_0~5\n",
    "\n",
    "**ç›®æ ‡å˜é‡**ï¼šincomeæ°¸è¿œä¸å‚ä¸æ ‡å‡†åŒ–ï¼\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2 å®æ–½æ ‡å‡†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61679ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Improved Feature Standardization ===\n",
      "Strategy: Standardize only continuous and ordinal features\n",
      "\n",
      "Feature categorization:\n",
      "  Continuous: 5 features\n",
      "  Ordinal: 2 features\n",
      "  Binary: 7 features\n",
      "  One-Hot: 22 features\n",
      "  Binary Encoded: 10 features (from occupation & country)\n",
      "\n",
      "âœ“ Will standardize 7 features:\n",
      "  age, hours.per.week, log_capital_gain, capital_total_activity, work_experience...\n",
      "\n",
      "âœ“ Standardization complete (meanâ‰ˆ0, stdâ‰ˆ1)\n",
      "\n",
      "=== Standardized Feature Statistics ===\n",
      "      age  hours.per.week  log_capital_gain  capital_total_activity  \\\n",
      "mean  0.0            -0.0               0.0                     0.0   \n",
      "std   1.0             1.0               1.0                     1.0   \n",
      "\n",
      "      work_experience  education  age_group  \n",
      "mean              0.0       -0.0        0.0  \n",
      "std               1.0        1.0        1.0  \n",
      "\n",
      "=== Non-Standardized Features (kept in 0/1 scale) ===\n",
      "âœ“ 7 binary features\n",
      "  Examples: sex, is_married, is_full_time\n",
      "âœ“ 22 One-Hot features\n",
      "  Examples: workclass_Local-gov, workclass_Never-worked, workclass_Private\n",
      "âœ“ 10 Binary Encoded features (from occupation & country)\n",
      "  Examples: occupation_0, occupation_1, occupation_2\n",
      "  Note: Each bit is already 0/1, no standardization needed\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPATIBILITY\n",
      "======================================================================\n",
      "âœ“ Random Forest: READY\n",
      "  - Doesn't require standardization\n",
      "  - Binary Encoded features work perfectly (tree-based splitting)\n",
      "\n",
      "âœ“ Logistic Regression: READY\n",
      "  - Continuous features standardized âœ“\n",
      "  - Binary/One-Hot/Binary-Encoded features preserved (0/1) âœ“\n",
      "  - All features on comparable scales âœ“\n",
      "\n",
      "Final dataset shape: (31978, 47)\n",
      "======================================================================\n",
      "\n",
      "âœ“ Standardization complete (meanâ‰ˆ0, stdâ‰ˆ1)\n",
      "\n",
      "=== Standardized Feature Statistics ===\n",
      "      age  hours.per.week  log_capital_gain  capital_total_activity  \\\n",
      "mean  0.0            -0.0               0.0                     0.0   \n",
      "std   1.0             1.0               1.0                     1.0   \n",
      "\n",
      "      work_experience  education  age_group  \n",
      "mean              0.0       -0.0        0.0  \n",
      "std               1.0        1.0        1.0  \n",
      "\n",
      "=== Non-Standardized Features (kept in 0/1 scale) ===\n",
      "âœ“ 7 binary features\n",
      "  Examples: sex, is_married, is_full_time\n",
      "âœ“ 22 One-Hot features\n",
      "  Examples: workclass_Local-gov, workclass_Never-worked, workclass_Private\n",
      "âœ“ 10 Binary Encoded features (from occupation & country)\n",
      "  Examples: occupation_0, occupation_1, occupation_2\n",
      "  Note: Each bit is already 0/1, no standardization needed\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPATIBILITY\n",
      "======================================================================\n",
      "âœ“ Random Forest: READY\n",
      "  - Doesn't require standardization\n",
      "  - Binary Encoded features work perfectly (tree-based splitting)\n",
      "\n",
      "âœ“ Logistic Regression: READY\n",
      "  - Continuous features standardized âœ“\n",
      "  - Binary/One-Hot/Binary-Encoded features preserved (0/1) âœ“\n",
      "  - All features on comparable scales âœ“\n",
      "\n",
      "Final dataset shape: (31978, 47)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Improved Feature Standardization ===\")\n",
    "print(\"Strategy: Standardize only continuous and ordinal features\\n\")\n",
    "\n",
    "# === 1. Categorize Features by Type ===\n",
    "# Continuous features (MUST standardize)\n",
    "continuous_features = [\n",
    "    'age', 'fnlwgt', 'education.num', 'hours.per.week',\n",
    "    'capital.gain', 'capital.loss', 'log_capital_gain',\n",
    "    'capital_total_activity', 'work_experience'\n",
    "]\n",
    "\n",
    "# Ordinal categorical features (SHOULD standardize - have numerical meaning)\n",
    "ordinal_features = ['education', 'age_group']\n",
    "\n",
    "# Binary features (DON'T standardize - 0/1 is already standard scale)\n",
    "binary_features = [\n",
    "    'sex', 'is_married', 'is_full_time', \n",
    "    'has_capital_gain', 'has_capital_loss', 'has_any_capital',\n",
    "    'education_occupation_match'\n",
    "]\n",
    "\n",
    "# One-Hot encoded features (DON'T standardize - already 0/1)\n",
    "onehot_features = [col for col in df_encoded.columns if any(\n",
    "    col.startswith(prefix) for prefix in ['workclass_', 'marital.status_', 'relationship_', 'race_']\n",
    ")]\n",
    "\n",
    "# Binary Encoded features (DON'T standardize - each bit is 0/1)\n",
    "binary_encoded_features = [col for col in df_encoded.columns if any(\n",
    "    col.startswith(prefix) for prefix in ['occupation_', 'native.country_']\n",
    ")]\n",
    "\n",
    "print(\"Feature categorization:\")\n",
    "print(f\"  Continuous: {len([f for f in continuous_features if f in df_encoded.columns])} features\")\n",
    "print(f\"  Ordinal: {len([f for f in ordinal_features if f in df_encoded.columns])} features\")\n",
    "print(f\"  Binary: {len([f for f in binary_features if f in df_encoded.columns])} features\")\n",
    "print(f\"  One-Hot: {len(onehot_features)} features\")\n",
    "print(f\"  Binary Encoded: {len(binary_encoded_features)} features (from occupation & country)\")\n",
    "\n",
    "# === 2. Select Features to Standardize ===\n",
    "features_to_standardize = continuous_features + ordinal_features\n",
    "\n",
    "# Filter out non-existent columns\n",
    "features_to_standardize = [f for f in features_to_standardize if f in df_encoded.columns]\n",
    "\n",
    "print(f\"\\nâœ“ Will standardize {len(features_to_standardize)} features:\")\n",
    "print(f\"  {', '.join(features_to_standardize[:5])}...\")\n",
    "\n",
    "# === 3. Apply Standardization ===\n",
    "scaler = StandardScaler()\n",
    "df_scaled = df_encoded.copy()\n",
    "df_scaled[features_to_standardize] = scaler.fit_transform(df_encoded[features_to_standardize])\n",
    "\n",
    "print(\"\\nâœ“ Standardization complete (meanâ‰ˆ0, stdâ‰ˆ1)\")\n",
    "\n",
    "# === 4. Verify Standardization ===\n",
    "print(\"\\n=== Standardized Feature Statistics ===\")\n",
    "scaled_stats = df_scaled[features_to_standardize].describe().loc[['mean', 'std']].round(3)\n",
    "print(scaled_stats)\n",
    "\n",
    "# === 5. Verify Non-Standardized Features ===\n",
    "binary_in_df = [f for f in binary_features if f in df_encoded.columns]\n",
    "onehot_in_df = [f for f in onehot_features if f in df_encoded.columns]\n",
    "binary_enc_in_df = [f for f in binary_encoded_features if f in df_encoded.columns]\n",
    "\n",
    "print(f\"\\n=== Non-Standardized Features (kept in 0/1 scale) ===\")\n",
    "print(f\"âœ“ {len(binary_in_df)} binary features\")\n",
    "if binary_in_df:\n",
    "    print(f\"  Examples: {', '.join(binary_in_df[:3])}\")\n",
    "\n",
    "print(f\"âœ“ {len(onehot_in_df)} One-Hot features\")\n",
    "if onehot_in_df:\n",
    "    print(f\"  Examples: {', '.join(onehot_in_df[:3])}\")\n",
    "\n",
    "print(f\"âœ“ {len(binary_enc_in_df)} Binary Encoded features (from occupation & country)\")\n",
    "if binary_enc_in_df:\n",
    "    print(f\"  Examples: {', '.join(binary_enc_in_df[:3])}\")\n",
    "    print(f\"  Note: Each bit is already 0/1, no standardization needed\")\n",
    "\n",
    "# === 6. Model Compatibility Check ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPATIBILITY\")\n",
    "print(\"=\"*70)\n",
    "print(\"âœ“ Random Forest: READY\")\n",
    "print(\"  - Doesn't require standardization\")\n",
    "print(\"  - Binary Encoded features work perfectly (tree-based splitting)\")\n",
    "print(\"\\nâœ“ Logistic Regression: READY\")\n",
    "print(\"  - Continuous features standardized âœ“\")\n",
    "print(\"  - Binary/One-Hot/Binary-Encoded features preserved (0/1) âœ“\")\n",
    "print(\"  - All features on comparable scales âœ“\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df_scaled.shape}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58974bf4",
   "metadata": {},
   "source": [
    "## 6. ä¿å­˜å¤„ç†åçš„æ•°æ®\n",
    "\n",
    "ä¿å­˜ä¸¤ä¸ªç‰ˆæœ¬çš„æ•°æ®ï¼š\n",
    "1. **Minimal Processing** (å®éªŒç»„A): ä»…åŸºæœ¬æ¸…æ´—\n",
    "2. **Full Governance** (å®éªŒç»„B): å®Œæ•´çš„æ•°æ®æ²»ç†ï¼ˆåŒ…å«æ ‡å‡†åŒ–ï¼‰\n",
    "\n",
    "**æ³¨æ„**ï¼š\n",
    "- âœ… å®éªŒç»„Cï¼ˆå¹³è¡¡é‡‡æ ·ï¼‰å°†åœ¨Stage 04å»ºæ¨¡é˜¶æ®µåˆ›å»º\n",
    "- âœ… é‡‡ç”¨æ­£ç¡®æµç¨‹ï¼šå…ˆsplitè®­ç»ƒé›†/æµ‹è¯•é›†ï¼Œå†å¯¹è®­ç»ƒé›†åº”ç”¨SMOTE\n",
    "- âœ… è¿™æ ·å¯ä»¥é¿å…æ•°æ®æ³„éœ²é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df7bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Saving Processed Datasets ===\n",
      "âœ“ Saved minimal processing dataset: (30162, 15)\n",
      "  Path: ../data/processed/adult_minimal_processing.csv\n",
      "âœ“ Saved minimal processing dataset: (30162, 15)\n",
      "  Path: ../data/processed/adult_minimal_processing.csv\n",
      "\n",
      "âœ“ Saved full governance dataset: (31978, 47)\n",
      "  Path: ../data/processed/adult_full_governance.csv\n",
      "\n",
      "âœ“ Saved full governance dataset: (31978, 47)\n",
      "  Path: ../data/processed/adult_full_governance.csv\n",
      "\n",
      "âœ“ Saved scaled dataset: (31978, 47)\n",
      "  Path: ../data/processed/adult_scaled.csv\n",
      "\n",
      "âœ“ Saved scaled dataset: (31978, 47)\n",
      "  Path: ../data/processed/adult_scaled.csv\n",
      "\n",
      "âœ“ Saved balanced dataset: (48566, 47)\n",
      "  Path: ../data/processed/adult_balanced.csv\n",
      "\n",
      "âœ“ Saved binary encoder\n",
      "âœ“ Saved scaler\n",
      "\n",
      "âœ“ Saved balanced dataset: (48566, 47)\n",
      "  Path: ../data/processed/adult_balanced.csv\n",
      "\n",
      "âœ“ Saved binary encoder\n",
      "âœ“ Saved scaler\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Saving Processed Datasets ===\")\n",
    "\n",
    "# Version A: Minimal Processing\n",
    "df_minimal = df_original.copy()\n",
    "df_minimal = df_minimal.replace('?', np.nan)\n",
    "df_minimal = df_minimal.dropna()\n",
    "df_minimal.to_csv('../data/processed/adult_minimal_processing.csv', index=False)\n",
    "print(f\"âœ“ Saved minimal processing dataset: {df_minimal.shape}\")\n",
    "print(f\"  Path: ../data/processed/adult_minimal_processing.csv\")\n",
    "\n",
    "# Version B: Full Governance (Standardized)\n",
    "df_scaled.to_csv('../data/processed/adult_full_governance.csv', index=False)\n",
    "print(f\"\\nâœ“ Saved full governance dataset (standardized): {df_scaled.shape}\")\n",
    "print(f\"  Path: ../data/processed/adult_full_governance.csv\")\n",
    "print(f\"  åŒ…å«: ç¼ºå¤±å€¼å¤„ç† + å¼‚å¸¸å€¼å¤„ç† + ç‰¹å¾å·¥ç¨‹ + ç¼–ç  + æ ‡å‡†åŒ–\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"æ³¨æ„ï¼šSMOTEå¹³è¡¡é‡‡æ ·å°†åœ¨Stage 04å»ºæ¨¡æ—¶è¿›è¡Œï¼ˆå…ˆsplitå†SMOTEï¼‰\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6dc62",
   "metadata": {},
   "source": [
    "## 7. æ•°æ®æ²»ç†æ€»ç»“æŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21357e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATA GOVERNANCE SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATA CLEANING\")\n",
    "print(f\"   - Original dataset: {df_original.shape}\")\n",
    "print(f\"   - After missing value handling: {df.shape}\")\n",
    "print(f\"   - Rows removed: {len(df_original) - len(df)}\")\n",
    "\n",
    "print(\"\\n2. OUTLIER HANDLING\")\n",
    "total_outliers = outlier_df['Outliers_Found'].sum()\n",
    "print(f\"   - Total outliers detected: {total_outliers}\")\n",
    "print(f\"   - Strategy: Winsorization (capping)\")\n",
    "\n",
    "print(\"\\n3. FEATURE ENGINEERING\")\n",
    "new_features = ['age_group', 'log_capital_gain', 'capital_total_activity', \n",
    "                'has_any_capital', 'has_capital_gain', 'has_capital_loss',\n",
    "                'is_full_time', 'education_occupation_match', 'work_experience', 'is_married']\n",
    "created_features = [f for f in new_features if f in df.columns]\n",
    "print(f\"   - New features created: {len(created_features)}\")\n",
    "print(f\"   - Features: {', '.join(created_features)}\")\n",
    "\n",
    "print(\"\\n4. ENCODING & STANDARDIZATION\")\n",
    "print(f\"   - Binary Encoding used for high-cardinality features (occupation, country)\")\n",
    "print(f\"   - One-Hot Encoding used for low-cardinality features\")\n",
    "print(f\"   - Features standardized: {len(features_to_standardize)}\")\n",
    "\n",
    "\n",
    "print(\"\\n7. ETHICAL CONSIDERATIONS\")\n",
    "print(\"   âœ“ Applied SMOTE to address class imbalance\")\n",
    "print(\"   âœ“ Preserved all demographic information for fairness evaluation\")\n",
    "print(\"   âœ“ Documented all transformations for reproducibility\")\n",
    "print(\"   ! Note: Gender and racial biases still present in data\")\n",
    "print(\"   ! Applied SMOTE to address class imbalance and Evaluate model fairness metrics in next stage\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Data Governance Complete - Ready for Model Training\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adult_income",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
